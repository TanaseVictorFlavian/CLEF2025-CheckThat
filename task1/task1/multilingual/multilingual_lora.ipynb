{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330bdb71556b4fa4a9fd753473f8aaf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10941 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41040' max='41040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41040/41040 1:52:12, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.654600</td>\n",
       "      <td>0.553153</td>\n",
       "      <td>0.716571</td>\n",
       "      <td>0.649917</td>\n",
       "      <td>0.379737</td>\n",
       "      <td>0.719718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.503500</td>\n",
       "      <td>0.542824</td>\n",
       "      <td>0.732383</td>\n",
       "      <td>0.688935</td>\n",
       "      <td>0.486004</td>\n",
       "      <td>0.696980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.369500</td>\n",
       "      <td>0.532246</td>\n",
       "      <td>0.738415</td>\n",
       "      <td>0.685353</td>\n",
       "      <td>0.444142</td>\n",
       "      <td>0.743675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.593500</td>\n",
       "      <td>0.511289</td>\n",
       "      <td>0.751394</td>\n",
       "      <td>0.710802</td>\n",
       "      <td>0.510528</td>\n",
       "      <td>0.734759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.580800</td>\n",
       "      <td>0.511646</td>\n",
       "      <td>0.761174</td>\n",
       "      <td>0.712390</td>\n",
       "      <td>0.473371</td>\n",
       "      <td>0.796914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.362500</td>\n",
       "      <td>0.492404</td>\n",
       "      <td>0.774609</td>\n",
       "      <td>0.742167</td>\n",
       "      <td>0.568987</td>\n",
       "      <td>0.759841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.240300</td>\n",
       "      <td>0.487676</td>\n",
       "      <td>0.784023</td>\n",
       "      <td>0.748979</td>\n",
       "      <td>0.556106</td>\n",
       "      <td>0.797230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.346200</td>\n",
       "      <td>0.470859</td>\n",
       "      <td>0.790147</td>\n",
       "      <td>0.763230</td>\n",
       "      <td>0.613822</td>\n",
       "      <td>0.770762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.573700</td>\n",
       "      <td>0.460562</td>\n",
       "      <td>0.794077</td>\n",
       "      <td>0.760436</td>\n",
       "      <td>0.568244</td>\n",
       "      <td>0.818117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.395300</td>\n",
       "      <td>0.449167</td>\n",
       "      <td>0.802395</td>\n",
       "      <td>0.773615</td>\n",
       "      <td>0.604162</td>\n",
       "      <td>0.812188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.812200</td>\n",
       "      <td>0.468861</td>\n",
       "      <td>0.799470</td>\n",
       "      <td>0.761178</td>\n",
       "      <td>0.540748</td>\n",
       "      <td>0.865240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.496700</td>\n",
       "      <td>0.451256</td>\n",
       "      <td>0.806599</td>\n",
       "      <td>0.772326</td>\n",
       "      <td>0.567253</td>\n",
       "      <td>0.861226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.369900</td>\n",
       "      <td>0.418863</td>\n",
       "      <td>0.813728</td>\n",
       "      <td>0.787699</td>\n",
       "      <td>0.628189</td>\n",
       "      <td>0.825252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.389300</td>\n",
       "      <td>0.439570</td>\n",
       "      <td>0.813363</td>\n",
       "      <td>0.785731</td>\n",
       "      <td>0.615556</td>\n",
       "      <td>0.835294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.298400</td>\n",
       "      <td>0.433394</td>\n",
       "      <td>0.815008</td>\n",
       "      <td>0.787233</td>\n",
       "      <td>0.614813</td>\n",
       "      <td>0.841071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\A_Facultate\\Master\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\peft\\utils\\other.py:1110: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /google-bert/bert-base-multilingual-cased/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001FBDDA160D0>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: e86c38f1-43a6-44d1-8249-4193419330b5)') - silently ignoring the lookup for the file config.json in google-bert/bert-base-multilingual-cased.\n",
      "  warnings.warn(\n",
      "d:\\A_Facultate\\Master\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\peft\\utils\\save_and_load.py:236: UserWarning: Could not find a config file in google-bert/bert-base-multilingual-cased - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "os.chdir(\"../..\")\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from task1.config import ProjectPaths\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "paths = ProjectPaths()\n",
    "\n",
    "# === 3. Set device ===\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# === 4. Load and preprocess data ===\n",
    "def load_raw_df(path):\n",
    "    df = pd.read_csv(path, sep='\\t')\n",
    "    df = df[df['label'].isin(['SUBJ', 'OBJ'])].copy()\n",
    "    df['labels'] = df['label'].map({'OBJ': 0, 'SUBJ': 1})\n",
    "    df = df[['sentence', 'labels']]\n",
    "    return df\n",
    "\n",
    "# Assuming paths.data_dir is a Path object pointing to the directory containing your language folders\n",
    "langs = [\"english\", \"arabic\", \"bulgarian\", \"italian\", \"german\"]\n",
    "aliases = [\"en\", \"ar\", \"bg\", \"it\", \"de\"]\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "for lang, alias in zip(langs, aliases):\n",
    "    train_df = load_raw_df(paths.data_dir / lang / f\"train_{alias}.tsv\")\n",
    "    train2_df   = load_raw_df(paths.data_dir / lang / f\"dev_{alias}.tsv\")\n",
    "    train3_df  = load_raw_df(paths.data_dir / lang / f\"dev_test_{alias}.tsv\")\n",
    "    # Add a column for language\n",
    "    # Append all to a single list\n",
    "    all_dfs.append(train_df)\n",
    "    all_dfs.append(train2_df)\n",
    "    all_dfs.append(train3_df)\n",
    "\n",
    "# Concatenate all DataFrames into a single big DataFrame\n",
    "\n",
    "train4_df = load_raw_df(paths.data_dir / \"multilingual\" / \"dev_test_multilingual.tsv\" )\n",
    "train_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# If needed as a HuggingFace Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "\n",
    "# === 5. Tokenization ===\n",
    "model_name = \"google-bert/bert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_fn(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"sentence\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_fn, batched=True)\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# === 6. Load model and add LoRA ===\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    target_modules=[\"query\", \"key\", \"value\"]\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config).to(device)\n",
    "\n",
    "# === 7. Define metrics ===\n",
    "f1 = evaluate.load(\"f1\")\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1_macro\": f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
    "        \"recall\": recall.compute(predictions=preds, references=labels)[\"recall\"],\n",
    "        \"precision\": precision.compute(predictions=preds, references=labels)[\"precision\"]\n",
    "    }\n",
    "\n",
    "# === 8. TrainingArguments ===\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=15,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    ")\n",
    "\n",
    "# === 9. Trainer ===\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    eval_dataset=train_dataset\n",
    ")\n",
    "\n",
    "# === 10. Train ===\n",
    "trainer.train()\n",
    "\n",
    "print(\"Training complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00159af337024acaae2f929a53342579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1982 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating multilingual\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='496' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [496/496 02:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6697618365287781,\n",
       " 'eval_accuracy': 0.722502522704339,\n",
       " 'eval_f1_macro': 0.6651948878413624,\n",
       " 'eval_recall': 0.49434571890145396,\n",
       " 'eval_precision': 0.56353591160221,\n",
       " 'eval_runtime': 21.3929,\n",
       " 'eval_samples_per_second': 92.648,\n",
       " 'eval_steps_per_second': 23.185,\n",
       " 'epoch': 15.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_test_df = load_raw_df(paths.data_dir / \"multilingual\" / \"test_multilingual_labeled.tsv\" )\n",
    "ml_test_ds = Dataset.from_pandas(ml_test_df)\n",
    "ml_test_ds = ml_test_ds.map(tokenize_fn, batched=True)\n",
    "ml_test_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "print(\"Evaluating multilingual\")\n",
    "\n",
    "# === 11. Evaluate on test set ===\n",
    "test_results = trainer.evaluate(eval_dataset=ml_test_ds)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>لكنهم مازالوا طلقاء حسم الجدل لفترة طويلة ظل ط...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>وأشدد على أهمية عدم التسرع في اتخاذ أي قرارات ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Das Fälschen von Totenscheinen kann als Ordnun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From the lack of vision, the lack of hope.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>من المتوقع أن تفقد البلاد حوالي 10 آلاف ثري ، ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  labels\n",
       "0  لكنهم مازالوا طلقاء حسم الجدل لفترة طويلة ظل ط...       0\n",
       "1  وأشدد على أهمية عدم التسرع في اتخاذ أي قرارات ...       0\n",
       "2  Das Fälschen von Totenscheinen kann als Ordnun...       0\n",
       "3         From the lack of vision, the lack of hope.       0\n",
       "4  من المتوقع أن تفقد البلاد حوالي 10 آلاف ثري ، ...       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6fc26681a83472ab68f298a87e39595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/297 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating zero-shot ukranian\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.115573763847351,\n",
       " 'eval_accuracy': 0.6666666666666666,\n",
       " 'eval_f1_macro': 0.6016339470796245,\n",
       " 'eval_recall': 0.5,\n",
       " 'eval_precision': 0.3939393939393939,\n",
       " 'eval_runtime': 3.4638,\n",
       " 'eval_samples_per_second': 85.745,\n",
       " 'eval_steps_per_second': 21.653,\n",
       " 'epoch': 15.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ukr_test_df = load_raw_df(paths.data_dir / \"ukrainian\" / \"test_ukr_labeled.tsv\" )\n",
    "ukr_test_ds = Dataset.from_pandas(ukr_test_df)\n",
    "ukr_test_ds = ukr_test_ds.map(tokenize_fn, batched=True)\n",
    "ukr_test_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "print(\"Evaluating zero-shot ukranian\")\n",
    "\n",
    "# === 11. Evaluate on test set ===\n",
    "test_results = trainer.evaluate(eval_dataset=ukr_test_ds)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5098aa24ff144900b1208b9eb7e46091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/206 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating zero-shot romanian\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.485209196805954,\n",
       " 'eval_accuracy': 0.8155339805825242,\n",
       " 'eval_f1_macro': 0.7643588199879591,\n",
       " 'eval_recall': 0.6923076923076923,\n",
       " 'eval_precision': 0.6206896551724138,\n",
       " 'eval_runtime': 2.3597,\n",
       " 'eval_samples_per_second': 87.3,\n",
       " 'eval_steps_per_second': 22.037,\n",
       " 'epoch': 15.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ro_test_df = load_raw_df(paths.data_dir / \"romanian\" / \"test_ro_labeled.tsv\" )\n",
    "ro_test_ds = Dataset.from_pandas(ro_test_df)\n",
    "ro_test_ds = ro_test_ds.map(tokenize_fn, batched=True)\n",
    "ro_test_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "print(\"Evaluating zero-shot romanian\")\n",
    "\n",
    "# === 11. Evaluate on test set ===\n",
    "test_results = trainer.evaluate(eval_dataset=ro_test_ds)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e32392ff58243d981bb37d24de745b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/351 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating zero-shot polish\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.3035749197006226,\n",
       " 'eval_accuracy': 0.6495726495726496,\n",
       " 'eval_f1_macro': 0.5737978419893975,\n",
       " 'eval_recall': 0.2484472049689441,\n",
       " 'eval_precision': 0.9523809523809523,\n",
       " 'eval_runtime': 3.8654,\n",
       " 'eval_samples_per_second': 90.806,\n",
       " 'eval_steps_per_second': 22.766,\n",
       " 'epoch': 15.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_test_df = load_raw_df(paths.data_dir / \"polish\" / \"test_pol_labeled.tsv\" )\n",
    "pl_test_ds = Dataset.from_pandas(pl_test_df)\n",
    "pl_test_ds = pl_test_ds.map(tokenize_fn, batched=True)\n",
    "pl_test_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "print(\"Evaluating zero-shot polish\")\n",
    "\n",
    "# === 11. Evaluate on test set ===\n",
    "test_results = trainer.evaluate(eval_dataset=pl_test_ds)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77fa0f9900534174b11901f661a7a1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/282 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating zero-shot greek\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.48859184980392456,\n",
       " 'eval_accuracy': 0.8191489361702128,\n",
       " 'eval_f1_macro': 0.677207945236225,\n",
       " 'eval_recall': 0.4782608695652174,\n",
       " 'eval_precision': 0.4489795918367347,\n",
       " 'eval_runtime': 3.1137,\n",
       " 'eval_samples_per_second': 90.567,\n",
       " 'eval_steps_per_second': 22.802,\n",
       " 'epoch': 15.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gk_test_df = load_raw_df(paths.data_dir / \"greek\" / \"test_gr_labeled.tsv\" )\n",
    "gk_test_ds = Dataset.from_pandas(gk_test_df)\n",
    "gk_test_ds = gk_test_ds.map(tokenize_fn, batched=True)\n",
    "gk_test_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "print(\"Evaluating zero-shot greek\")\n",
    "\n",
    "# === 11. Evaluate on test set ===\n",
    "test_results = trainer.evaluate(eval_dataset=gk_test_ds)\n",
    "test_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
