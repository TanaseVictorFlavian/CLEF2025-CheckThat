{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "947d5b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.chdir(\"../..\")\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq, AutoModelForSequenceClassification\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from task1.config import ProjectPaths\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "paths = ProjectPaths()\n",
    "\n",
    "# === 3. Set device ===\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# === 4. Load and preprocess data ===\n",
    "def load_dataset(path):\n",
    "    df = pd.read_csv(path, sep='\\t')\n",
    "    df = df[df['label'].isin(['SUBJ', 'OBJ'])].copy()\n",
    "    df['label'] = df['label'].map({'OBJ': 0, 'SUBJ': 1})\n",
    "    df = df[['sentence', 'label']]\n",
    "    return Dataset.from_pandas(df)\n",
    "\n",
    "train_dataset = load_dataset(paths.english_data_dir / \"train_en.tsv\")\n",
    "val_dataset   = load_dataset(paths.english_data_dir / \"dev_en.tsv\")\n",
    "test_dataset  = load_dataset(paths.english_data_dir / \"dev_test_en.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0709c78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe093f2a283466ab9f7fdbcd584d58b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/830 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574fbab5f1de4a1cbf48290942b129e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/462 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8a04d89a574dcd936515c1a13e9503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/484 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"microsoft/deberta-v3-base\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "# The AutoTokenizer will correctly load the specific DebertaV2Tokenizer needed.\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_fn(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"sentence\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_fn, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_fn, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_fn, batched=True)\n",
    "\n",
    "train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
    "val_dataset = val_dataset.rename_column(\"label\", \"labels\")\n",
    "test_dataset = test_dataset.rename_column(\"label\", \"labels\")\n",
    "\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bab7dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    # The base is a BERT model, so we use its target modules\n",
    "    target_modules=[\"query_proj\", \"key_proj\", \"value_proj\", \"dense\"] \n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0aa322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = evaluate.load(\"f1\")\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1_macro\": f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"]\n",
    "    }\n",
    "\n",
    "# === 8. TrainingArguments ===\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a0911f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2080' max='2080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2080/2080 44:44, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.641800</td>\n",
       "      <td>0.749929</td>\n",
       "      <td>0.480519</td>\n",
       "      <td>0.324561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.642300</td>\n",
       "      <td>0.506044</td>\n",
       "      <td>0.768398</td>\n",
       "      <td>0.766903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.151100</td>\n",
       "      <td>0.505919</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.237400</td>\n",
       "      <td>0.615214</td>\n",
       "      <td>0.794372</td>\n",
       "      <td>0.794371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.475300</td>\n",
       "      <td>0.613986</td>\n",
       "      <td>0.816017</td>\n",
       "      <td>0.815477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.304800</td>\n",
       "      <td>0.667361</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.809520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.213700</td>\n",
       "      <td>0.767627</td>\n",
       "      <td>0.796537</td>\n",
       "      <td>0.796441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>0.800240</td>\n",
       "      <td>0.798701</td>\n",
       "      <td>0.798655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.144500</td>\n",
       "      <td>0.840810</td>\n",
       "      <td>0.796537</td>\n",
       "      <td>0.796441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.109800</td>\n",
       "      <td>0.773799</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.817840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='121' max='121' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [121/121 01:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.8570545315742493,\n",
       " 'eval_accuracy': 0.8347107438016529,\n",
       " 'eval_f1_macro': 0.7270163564579808,\n",
       " 'eval_runtime': 61.5581,\n",
       " 'eval_samples_per_second': 7.862,\n",
       " 'eval_steps_per_second': 1.966,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# === 10. Train ===\n",
    "trainer.train()\n",
    "\n",
    "# === 11. Evaluate on test set ===\n",
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
