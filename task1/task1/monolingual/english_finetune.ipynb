{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "947d5b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0615 10:51:12.747000 28716 Lib\\site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "os.chdir(\"../..\")\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq, AutoModelForSequenceClassification\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from task1.config import ProjectPaths\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "paths = ProjectPaths()\n",
    "\n",
    "# === 3. Set device ===\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# === 4. Load and preprocess data ===\n",
    "def load_datasets(path):\n",
    "    df = pd.read_csv(path, sep='\\t')\n",
    "    df = df[df['label'].isin(['SUBJ', 'OBJ'])].copy()\n",
    "    df['label'] = df['label'].map({'OBJ': 0, 'SUBJ': 1})\n",
    "    df = df[['sentence', 'label']]\n",
    "    return Dataset.from_pandas(df)\n",
    "\n",
    "train_dataset = load_datasets(paths.english_data_dir / \"train_en.tsv\")\n",
    "val_dataset   = load_datasets(paths.english_data_dir / \"dev_en.tsv\")\n",
    "test_dataset  = load_datasets(paths.english_data_dir / \"dev_test_en.tsv\")\n",
    "competition_test_dataset = load_datasets(paths.english_data_dir / \"test_en_labeled.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b75e6911",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "train_dataset_stage1 = dataset[\"train\"]\n",
    "val_dataset_stage1 = dataset[\"validation\"]\n",
    "\n",
    "small_train_dataset = train_dataset_stage1.select(range(1000))  # Use only 1000 examples for training\n",
    "small_val_dataset = val_dataset_stage1.select(range(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dae9f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"microsoft/deberta-v3-base\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455d9fac",
   "metadata": {},
   "source": [
    "STAGE 1 FINETUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ba04012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_stage1(examples):\n",
    "    # The text column in this dataset is named 'text'\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6f44200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b8cf494e6f42d3a569b5f8e3dae3d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cbd70e5376349be80782c2a2a80776b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = small_train_dataset.map(tokenize_stage1, batched=True)\n",
    "tokenized_val_dataset = small_val_dataset.map(tokenize_stage1, batched=True)\n",
    "\n",
    "# The 'label' column is already correct, just need to set the format\n",
    "tokenized_train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "tokenized_val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "# The Trainer works best when the label column is named 'labels'\n",
    "tokenized_train_dataset = tokenized_train_dataset.rename_column(\"label\", \"labels\")\n",
    "tokenized_val_dataset = tokenized_val_dataset.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5dbcd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    target_modules=[\"query_proj\", \"key_proj\", \"value_proj\", \"dense\"] \n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a792cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = evaluate.load(\"f1\")\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1_macro\": f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
    "        \"precision\": precision.compute(predictions=preds, references=labels, average=\"macro\")[\"precision\"],\n",
    "        \"recall\": recall.compute(predictions=preds, references=labels, average=\"macro\")[\"recall\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df6d6299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 8. TrainingArguments ===\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=5,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b80f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# === 10. Train ===\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(\"./results/stage1-rotten-tomatoes/final_checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7695b09",
   "metadata": {},
   "source": [
    "STAGE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0709c78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536d902367b04e6eabf086b5543ef679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/830 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123c45af6b3a43b58af173e4579e62f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/462 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b22bd7934d4974a977e367ea9d2a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/484 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5132f6c5d82d4f44b1712df304a6eb1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_fn(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"sentence\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_fn, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_fn, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_fn, batched=True)\n",
    "competition_test_dataset = competition_test_dataset.map(tokenize_fn, batched=True)\n",
    "\n",
    "train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
    "val_dataset = val_dataset.rename_column(\"label\", \"labels\")\n",
    "test_dataset = test_dataset.rename_column(\"label\", \"labels\")\n",
    "competition_test_dataset = competition_test_dataset.rename_column(\"label\", \"labels\")\n",
    "\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "competition_test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb7ef4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "model = PeftModel.from_pretrained(base_model, \"./results/stage1-rotten-tomatoes/final_checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bab7dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    target_modules=[\"query_proj\", \"key_proj\", \"value_proj\", \"dense\"] \n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0aa322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 8. TrainingArguments ===\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a0911f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m trainer = Trainer(\n\u001b[32m      2\u001b[39m     model=model,\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     args=\u001b[43mtraining_args\u001b[49m,\n\u001b[32m      4\u001b[39m     train_dataset=train_dataset,\n\u001b[32m      5\u001b[39m     eval_dataset=val_dataset,\n\u001b[32m      6\u001b[39m     compute_metrics=compute_metrics\n\u001b[32m      7\u001b[39m )\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# === 10. Train ===\u001b[39;00m\n\u001b[32m     10\u001b[39m trainer.train()\n",
      "\u001b[31mNameError\u001b[39m: name 'training_args' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# === 10. Train ===\n",
    "trainer.train()\n",
    "\n",
    "# === 11. Evaluate on test set ===\n",
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
