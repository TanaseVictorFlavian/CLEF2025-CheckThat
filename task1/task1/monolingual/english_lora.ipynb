{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50183bb0ea94431fbbfb212e2a301703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/830 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43050549a62346e689d33cd9474351fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/462 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf1cc45accaf40c28ea5955820ccb66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/484 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3120' max='3120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3120/3120 04:22, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.503700</td>\n",
       "      <td>0.664474</td>\n",
       "      <td>0.593074</td>\n",
       "      <td>0.551928</td>\n",
       "      <td>0.279167</td>\n",
       "      <td>0.817073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.610400</td>\n",
       "      <td>0.521988</td>\n",
       "      <td>0.748918</td>\n",
       "      <td>0.748687</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.798077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.245500</td>\n",
       "      <td>0.561920</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.756095</td>\n",
       "      <td>0.654167</td>\n",
       "      <td>0.844086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.264600</td>\n",
       "      <td>0.517118</td>\n",
       "      <td>0.768398</td>\n",
       "      <td>0.768397</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.798206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.536600</td>\n",
       "      <td>0.529657</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785085</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.785425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.278100</td>\n",
       "      <td>0.560687</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>0.774685</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.826923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.273200</td>\n",
       "      <td>0.583825</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.778719</td>\n",
       "      <td>0.704167</td>\n",
       "      <td>0.845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.252900</td>\n",
       "      <td>0.642672</td>\n",
       "      <td>0.777056</td>\n",
       "      <td>0.775287</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.878453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.133100</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.778956</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.834951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.710481</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>0.772831</td>\n",
       "      <td>0.654167</td>\n",
       "      <td>0.882022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.507800</td>\n",
       "      <td>0.713419</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>0.773358</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.416800</td>\n",
       "      <td>0.664708</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785689</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>0.824885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.213300</td>\n",
       "      <td>0.706473</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>0.773939</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.854167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.403400</td>\n",
       "      <td>0.743062</td>\n",
       "      <td>0.770563</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.864130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.208200</td>\n",
       "      <td>0.753943</td>\n",
       "      <td>0.770563</td>\n",
       "      <td>0.768830</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.868132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n",
      "Evaluating on test set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='121' max='121' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [121/121 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6249175071716309,\n",
       " 'eval_accuracy': 0.7995867768595041,\n",
       " 'eval_f1_macro': 0.70607348788871,\n",
       " 'eval_recall': 0.4672131147540984,\n",
       " 'eval_precision': 0.6404494382022472,\n",
       " 'eval_runtime': 3.0367,\n",
       " 'eval_samples_per_second': 159.383,\n",
       " 'eval_steps_per_second': 39.846,\n",
       " 'epoch': 15.0}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "os.chdir(\"../..\")\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from task1.config import ProjectPaths\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "paths = ProjectPaths()\n",
    "\n",
    "# === 3. Set device ===\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# === 4. Load and preprocess data ===\n",
    "def load_dataset(path):\n",
    "    df = pd.read_csv(path, sep='\\t')\n",
    "    df = df[df['label'].isin(['SUBJ', 'OBJ'])].copy()\n",
    "    df['labels'] = df['label'].map({'OBJ': 0, 'SUBJ': 1})\n",
    "    df = df[['sentence', 'labels']]\n",
    "    return Dataset.from_pandas(df)\n",
    "\n",
    "train_dataset = load_dataset(paths.english_data_dir / \"train_en.tsv\")\n",
    "val_dataset   = load_dataset(paths.english_data_dir / \"dev_en.tsv\")\n",
    "test_dataset  = load_dataset(paths.english_data_dir / \"dev_test_en.tsv\")\n",
    "\n",
    "\n",
    "\n",
    "# === 5. Tokenization ===\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_fn(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"sentence\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_fn, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_fn, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_fn, batched=True)\n",
    "\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# === 6. Load model and add LoRA ===\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    target_modules=[\"q_lin\", \"k_lin\", \"v_lin\", \"out_lin\"]\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config).to(device)\n",
    "\n",
    "# === 7. Define metrics ===\n",
    "f1 = evaluate.load(\"f1\")\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1_macro\": f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
    "        \"recall\": recall.compute(predictions=preds, references=labels)[\"recall\"],\n",
    "        \"precision\": precision.compute(predictions=preds, references=labels)[\"precision\"]\n",
    "    }\n",
    "\n",
    "# === 8. TrainingArguments ===\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=15,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    ")\n",
    "\n",
    "# === 9. Trainer ===\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# === 10. Train ===\n",
    "trainer.train()\n",
    "\n",
    "print(\"Training complete\")\n",
    "\n",
    "print(\"Evaluating on test set\")\n",
    "# === 11. Evaluate on test set ===\n",
    "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_runtime': 3.1051,\n",
       " 'test_samples_per_second': 155.871,\n",
       " 'test_steps_per_second': 38.968}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results =trainer.predict(test_dataset)\n",
    "test_results.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
