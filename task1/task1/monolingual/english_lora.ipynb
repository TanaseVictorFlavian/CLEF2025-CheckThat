{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a02427963004bcf9a82fc1e450a2cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/830 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b7d150e42946f2a89f5eea2c70cc4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/462 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e27127154e94fc3834cdacae8b6bf9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/484 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3120' max='3120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3120/3120 04:00, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.494700</td>\n",
       "      <td>0.669466</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.551468</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.604500</td>\n",
       "      <td>0.556190</td>\n",
       "      <td>0.720779</td>\n",
       "      <td>0.717859</td>\n",
       "      <td>0.595833</td>\n",
       "      <td>0.817143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.285800</td>\n",
       "      <td>0.590769</td>\n",
       "      <td>0.731602</td>\n",
       "      <td>0.728158</td>\n",
       "      <td>0.595833</td>\n",
       "      <td>0.841176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.289300</td>\n",
       "      <td>0.532931</td>\n",
       "      <td>0.770563</td>\n",
       "      <td>0.770352</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.822115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.539700</td>\n",
       "      <td>0.533729</td>\n",
       "      <td>0.770563</td>\n",
       "      <td>0.770546</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.796460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.319100</td>\n",
       "      <td>0.575651</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>0.774380</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.330100</td>\n",
       "      <td>0.678092</td>\n",
       "      <td>0.744589</td>\n",
       "      <td>0.740207</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.876543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.290900</td>\n",
       "      <td>0.668493</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.759521</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.869318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.107500</td>\n",
       "      <td>0.654152</td>\n",
       "      <td>0.770563</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.864130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.199600</td>\n",
       "      <td>0.676017</td>\n",
       "      <td>0.764069</td>\n",
       "      <td>0.762008</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.865922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.514000</td>\n",
       "      <td>0.727060</td>\n",
       "      <td>0.764069</td>\n",
       "      <td>0.761602</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.874286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.378800</td>\n",
       "      <td>0.680669</td>\n",
       "      <td>0.781385</td>\n",
       "      <td>0.780636</td>\n",
       "      <td>0.695833</td>\n",
       "      <td>0.856410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.285900</td>\n",
       "      <td>0.708794</td>\n",
       "      <td>0.768398</td>\n",
       "      <td>0.766903</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.859459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0.758450</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.750554</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.862069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.196800</td>\n",
       "      <td>0.762277</td>\n",
       "      <td>0.751082</td>\n",
       "      <td>0.748250</td>\n",
       "      <td>0.620833</td>\n",
       "      <td>0.861272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n",
      "Evaluating on test set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='121' max='121' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [121/121 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.620328426361084,\n",
       " 'eval_accuracy': 0.8016528925619835,\n",
       " 'eval_f1_macro': 0.7018786572220511,\n",
       " 'eval_recall': 0.4426229508196721,\n",
       " 'eval_precision': 0.6585365853658537,\n",
       " 'eval_runtime': 2.9591,\n",
       " 'eval_samples_per_second': 163.562,\n",
       " 'eval_steps_per_second': 40.891,\n",
       " 'epoch': 15.0}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "os.chdir(\"../..\")\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from task1.config import ProjectPaths\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "paths = ProjectPaths()\n",
    "\n",
    "# === 3. Set device ===\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# === 4. Load and preprocess data ===\n",
    "def load_dataset(path):\n",
    "    df = pd.read_csv(path, sep='\\t')\n",
    "    df = df[df['label'].isin(['SUBJ', 'OBJ'])].copy()\n",
    "    df['labels'] = df['label'].map({'OBJ': 0, 'SUBJ': 1})\n",
    "    df = df[['sentence', 'labels']]\n",
    "    return Dataset.from_pandas(df)\n",
    "\n",
    "train_dataset = load_dataset(paths.english_data_dir / \"train_en.tsv\")\n",
    "val_dataset   = load_dataset(paths.english_data_dir / \"dev_en.tsv\")\n",
    "test_dataset  = load_dataset(paths.english_data_dir / \"dev_test_en.tsv\")\n",
    "\n",
    "\n",
    "\n",
    "# === 5. Tokenization ===\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_fn(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"sentence\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_fn, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_fn, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_fn, batched=True)\n",
    "\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# === 6. Load model and add LoRA ===\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    target_modules=[\"q_lin\", \"k_lin\", \"v_lin\", \"out_lin\"]\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config).to(device)\n",
    "\n",
    "# === 7. Define metrics ===\n",
    "f1 = evaluate.load(\"f1\")\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1_macro\": f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
    "        \"recall\": recall.compute(predictions=preds, references=labels)[\"recall\"],\n",
    "        \"precision\": precision.compute(predictions=preds, references=labels)[\"precision\"]\n",
    "    }\n",
    "\n",
    "# === 8. TrainingArguments ===\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=15,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    ")\n",
    "\n",
    "# === 9. Trainer ===\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# === 10. Train ===\n",
    "trainer.train()\n",
    "\n",
    "print(\"Training complete\")\n",
    "\n",
    "print(\"Evaluating on test set\")\n",
    "# === 11. Evaluate on test set ===\n",
    "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_runtime': 3.1051,\n",
       " 'test_samples_per_second': 155.871,\n",
       " 'test_steps_per_second': 38.968}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results =trainer.predict(test_dataset)\n",
    "test_results.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1885bb80f9f348139fa96c891f32c706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\A_Facultate\\Master\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\flavi\\.cache\\huggingface\\hub\\models--xlm-roberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7be6cd783514fcd879e09ade555ff8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb49a594c214df19501b617db69418b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d5aa23a9364aae87dd1f59c9229596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8ad1f6476242bbb3a55240d50bea30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/830 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3b19e9f53a4c2aa29e7b6b92ffb6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/462 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b442363f2274ba5bab51f344846ae0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/484 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9cbd47ecf44832b7f4f79bb5579d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3120' max='3120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3120/3120 07:27, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.634500</td>\n",
       "      <td>0.773805</td>\n",
       "      <td>0.480519</td>\n",
       "      <td>0.324561</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.677500</td>\n",
       "      <td>0.643038</td>\n",
       "      <td>0.599567</td>\n",
       "      <td>0.577757</td>\n",
       "      <td>0.358333</td>\n",
       "      <td>0.735043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.502200</td>\n",
       "      <td>0.778800</td>\n",
       "      <td>0.608225</td>\n",
       "      <td>0.576200</td>\n",
       "      <td>0.320833</td>\n",
       "      <td>0.810526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.487900</td>\n",
       "      <td>0.655101</td>\n",
       "      <td>0.707792</td>\n",
       "      <td>0.706105</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.780749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.668800</td>\n",
       "      <td>0.608810</td>\n",
       "      <td>0.731602</td>\n",
       "      <td>0.731421</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.747863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.481500</td>\n",
       "      <td>0.716128</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.683664</td>\n",
       "      <td>0.545833</td>\n",
       "      <td>0.789157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>0.722276</td>\n",
       "      <td>0.694805</td>\n",
       "      <td>0.689390</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.807453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.452000</td>\n",
       "      <td>0.750744</td>\n",
       "      <td>0.729437</td>\n",
       "      <td>0.728367</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.797927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.440300</td>\n",
       "      <td>0.839097</td>\n",
       "      <td>0.712121</td>\n",
       "      <td>0.704329</td>\n",
       "      <td>0.529167</td>\n",
       "      <td>0.863946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.372200</td>\n",
       "      <td>0.844130</td>\n",
       "      <td>0.712121</td>\n",
       "      <td>0.705158</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>0.854305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.870400</td>\n",
       "      <td>0.846086</td>\n",
       "      <td>0.720779</td>\n",
       "      <td>0.715141</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.853503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.626300</td>\n",
       "      <td>0.745230</td>\n",
       "      <td>0.746753</td>\n",
       "      <td>0.746486</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.797101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.473700</td>\n",
       "      <td>0.800667</td>\n",
       "      <td>0.725108</td>\n",
       "      <td>0.722706</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.815642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.432400</td>\n",
       "      <td>0.890783</td>\n",
       "      <td>0.718615</td>\n",
       "      <td>0.711610</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.340600</td>\n",
       "      <td>0.905891</td>\n",
       "      <td>0.718615</td>\n",
       "      <td>0.711610</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\A_Facultate\\Master\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n",
      "Evaluating on test set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='121' max='121' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [121/121 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7191133499145508, 'eval_accuracy': 0.7933884297520661, 'eval_f1_macro': 0.6725747530780679, 'eval_recall': 0.36885245901639346, 'eval_precision': 0.6617647058823529, 'eval_runtime': 5.3618, 'eval_samples_per_second': 90.267, 'eval_steps_per_second': 22.567, 'epoch': 15.0}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "os.chdir(\"../..\")\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from task1.config import ProjectPaths\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "paths = ProjectPaths()\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_dataset(path):\n",
    "    df = pd.read_csv(path, sep='\\t')\n",
    "    df = df[df['label'].isin(['SUBJ', 'OBJ'])].copy()\n",
    "    df['labels'] = df['label'].map({'OBJ': 0, 'SUBJ': 1})\n",
    "    df = df[['sentence', 'labels']]\n",
    "    return Dataset.from_pandas(df)\n",
    "\n",
    "train_dataset = load_dataset(paths.english_data_dir / \"train_en.tsv\")\n",
    "val_dataset = load_dataset(paths.english_data_dir / \"dev_en.tsv\")\n",
    "test_dataset = load_dataset(paths.english_data_dir / \"dev_test_en.tsv\")\n",
    "\n",
    "# Tokenization\n",
    "model_name = \"xlm-roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_fn(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"sentence\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_fn, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_fn, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_fn, batched=True)\n",
    "\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Load model and add LoRA\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    target_modules=[\"query\", \"key\", \"value\"]  # Adjust target modules for XLM-RoBERTa\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config).to(device)\n",
    "\n",
    "# Define metrics\n",
    "f1 = evaluate.load(\"f1\")\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1_macro\": f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
    "        \"recall\": recall.compute(predictions=preds, references=labels)[\"recall\"],\n",
    "        \"precision\": precision.compute(predictions=preds, references=labels)[\"precision\"]\n",
    "    }\n",
    "\n",
    "# TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=15,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()\n",
    "\n",
    "print(\"Training complete\")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"Evaluating on test set\")\n",
    "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "print(test_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c87a4917b24453b3f8d26dd19ea478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/830 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afddc3f9e2e7457ab6bbe7a9e232b7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/462 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87be83e8b7a54154b4ae6ed6dc2af152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/484 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3120' max='3120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3120/3120 07:27, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.642900</td>\n",
       "      <td>0.778054</td>\n",
       "      <td>0.480519</td>\n",
       "      <td>0.324561</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.625900</td>\n",
       "      <td>0.637248</td>\n",
       "      <td>0.621212</td>\n",
       "      <td>0.589183</td>\n",
       "      <td>0.329167</td>\n",
       "      <td>0.849462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.318100</td>\n",
       "      <td>0.760018</td>\n",
       "      <td>0.655844</td>\n",
       "      <td>0.637844</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.840336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.479100</td>\n",
       "      <td>0.658077</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.737181</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.848837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.638800</td>\n",
       "      <td>0.626238</td>\n",
       "      <td>0.770563</td>\n",
       "      <td>0.769717</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.845361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.493400</td>\n",
       "      <td>0.629018</td>\n",
       "      <td>0.764069</td>\n",
       "      <td>0.763483</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.829146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.317800</td>\n",
       "      <td>0.793180</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.734047</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.860606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.423700</td>\n",
       "      <td>0.769811</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.750988</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.853933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.313500</td>\n",
       "      <td>0.821742</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.738721</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.862275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.158600</td>\n",
       "      <td>0.812664</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.759725</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.865169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.461600</td>\n",
       "      <td>0.792619</td>\n",
       "      <td>0.770563</td>\n",
       "      <td>0.769834</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.841837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.791900</td>\n",
       "      <td>0.825620</td>\n",
       "      <td>0.764069</td>\n",
       "      <td>0.763136</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.839378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.276900</td>\n",
       "      <td>0.879692</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.750988</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.853933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.321400</td>\n",
       "      <td>0.899609</td>\n",
       "      <td>0.748918</td>\n",
       "      <td>0.746178</td>\n",
       "      <td>0.620833</td>\n",
       "      <td>0.856322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.341000</td>\n",
       "      <td>0.905916</td>\n",
       "      <td>0.746753</td>\n",
       "      <td>0.743872</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.855491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\A_Facultate\\Master\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n",
      "Evaluating on test set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='121' max='121' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [121/121 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.8003444075584412,\n",
       " 'eval_accuracy': 0.8016528925619835,\n",
       " 'eval_f1_macro': 0.7100928421683139,\n",
       " 'eval_recall': 0.47540983606557374,\n",
       " 'eval_precision': 0.6444444444444445,\n",
       " 'eval_runtime': 5.5425,\n",
       " 'eval_samples_per_second': 87.325,\n",
       " 'eval_steps_per_second': 21.831,\n",
       " 'epoch': 15.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "os.chdir(\"../..\")\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from task1.config import ProjectPaths\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "paths = ProjectPaths()\n",
    "\n",
    "# === 3. Set device ===\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# === 4. Load and preprocess data ===\n",
    "def load_dataset(path):\n",
    "    df = pd.read_csv(path, sep='\\t')\n",
    "    df = df[df['label'].isin(['SUBJ', 'OBJ'])].copy()\n",
    "    df['labels'] = df['label'].map({'OBJ': 0, 'SUBJ': 1})\n",
    "    df = df[['sentence', 'labels']]\n",
    "    return Dataset.from_pandas(df)\n",
    "\n",
    "train_dataset = load_dataset(paths.english_data_dir / \"train_en.tsv\")\n",
    "val_dataset   = load_dataset(paths.english_data_dir / \"dev_en.tsv\")\n",
    "test_dataset  = load_dataset(paths.english_data_dir / \"dev_test_en.tsv\")\n",
    "\n",
    "\n",
    "\n",
    "# === 5. Tokenization ===\n",
    "model_name = \"google-bert/bert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_fn(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"sentence\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_fn, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_fn, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_fn, batched=True)\n",
    "\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# === 6. Load model and add LoRA ===\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    target_modules=[\"query\", \"key\", \"value\"]\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config).to(device)\n",
    "\n",
    "# === 7. Define metrics ===\n",
    "f1 = evaluate.load(\"f1\")\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1_macro\": f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
    "        \"recall\": recall.compute(predictions=preds, references=labels)[\"recall\"],\n",
    "        \"precision\": precision.compute(predictions=preds, references=labels)[\"precision\"]\n",
    "    }\n",
    "\n",
    "# === 8. TrainingArguments ===\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=15,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    ")\n",
    "\n",
    "# === 9. Trainer ===\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# === 10. Train ===\n",
    "trainer.train()\n",
    "\n",
    "print(\"Training complete\")\n",
    "\n",
    "print(\"Evaluating on test set\")\n",
    "# === 11. Evaluate on test set ===\n",
    "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf98dc5a5d0e45c38bb7da7d9e543c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\A_Facultate\\Master\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\flavi\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12cff64a93b4427a2f14454526e0c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda1a701a0104b4ea9c4447bc3312b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9ce236abc84aef8cf1d398f9073bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/830 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef6367aa02d45c6871cb52e2a367dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/462 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc5fcbf4fdf46b1903cbcbe94979c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/484 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d117a0f394184d11bb1786eabb148828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3120' max='3120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3120/3120 03:58, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.615400</td>\n",
       "      <td>0.721338</td>\n",
       "      <td>0.487013</td>\n",
       "      <td>0.364276</td>\n",
       "      <td>0.045833</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.671000</td>\n",
       "      <td>0.638464</td>\n",
       "      <td>0.582251</td>\n",
       "      <td>0.540673</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.783133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.449900</td>\n",
       "      <td>0.623101</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.629727</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>0.539783</td>\n",
       "      <td>0.716450</td>\n",
       "      <td>0.716066</td>\n",
       "      <td>0.654167</td>\n",
       "      <td>0.765854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.515600</td>\n",
       "      <td>0.544011</td>\n",
       "      <td>0.733766</td>\n",
       "      <td>0.733615</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.777251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.355600</td>\n",
       "      <td>0.578736</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.737553</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.796020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.322500</td>\n",
       "      <td>0.681708</td>\n",
       "      <td>0.716450</td>\n",
       "      <td>0.713972</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.804469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.199700</td>\n",
       "      <td>0.638494</td>\n",
       "      <td>0.744589</td>\n",
       "      <td>0.744282</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.796117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.193700</td>\n",
       "      <td>0.716176</td>\n",
       "      <td>0.733766</td>\n",
       "      <td>0.731855</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.819672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.191900</td>\n",
       "      <td>0.705840</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.739669</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.335400</td>\n",
       "      <td>0.723867</td>\n",
       "      <td>0.751082</td>\n",
       "      <td>0.750567</td>\n",
       "      <td>0.679167</td>\n",
       "      <td>0.810945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.285900</td>\n",
       "      <td>0.749666</td>\n",
       "      <td>0.751082</td>\n",
       "      <td>0.750464</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.814070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.302700</td>\n",
       "      <td>0.771705</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.752579</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.285200</td>\n",
       "      <td>0.809794</td>\n",
       "      <td>0.751082</td>\n",
       "      <td>0.750098</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.823834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.311100</td>\n",
       "      <td>0.817543</td>\n",
       "      <td>0.748918</td>\n",
       "      <td>0.747992</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.819588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n",
      "Evaluating on test set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='121' max='121' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [121/121 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6768895983695984,\n",
       " 'eval_accuracy': 0.78099173553719,\n",
       " 'eval_f1_macro': 0.7095824653563989,\n",
       " 'eval_recall': 0.5655737704918032,\n",
       " 'eval_precision': 0.5655737704918032,\n",
       " 'eval_runtime': 2.9297,\n",
       " 'eval_samples_per_second': 165.202,\n",
       " 'eval_steps_per_second': 41.301,\n",
       " 'epoch': 15.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "os.chdir(\"../..\")\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from task1.config import ProjectPaths\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "paths = ProjectPaths()\n",
    "\n",
    "# === 3. Set device ===\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# === 4. Load and preprocess data ===\n",
    "def load_dataset(path):\n",
    "    df = pd.read_csv(path, sep='\\t')\n",
    "    df = df[df['label'].isin(['SUBJ', 'OBJ'])].copy()\n",
    "    df['labels'] = df['label'].map({'OBJ': 0, 'SUBJ': 1})\n",
    "    df = df[['sentence', 'labels']]\n",
    "    return Dataset.from_pandas(df)\n",
    "\n",
    "train_dataset = load_dataset(paths.english_data_dir / \"train_en.tsv\")\n",
    "val_dataset   = load_dataset(paths.english_data_dir / \"dev_en.tsv\")\n",
    "test_dataset  = load_dataset(paths.english_data_dir / \"dev_test_en.tsv\")\n",
    "\n",
    "\n",
    "\n",
    "# === 5. Tokenization ===\n",
    "model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_fn(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"sentence\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_fn, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_fn, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_fn, batched=True)\n",
    "\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# === 6. Load model and add LoRA ===\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    target_modules=[\"q_lin\", \"k_lin\", \"v_lin\", \"out_lin\"]\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config).to(device)\n",
    "\n",
    "# === 7. Define metrics ===\n",
    "f1 = evaluate.load(\"f1\")\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1_macro\": f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
    "        \"recall\": recall.compute(predictions=preds, references=labels)[\"recall\"],\n",
    "        \"precision\": precision.compute(predictions=preds, references=labels)[\"precision\"]\n",
    "    }\n",
    "\n",
    "# === 8. TrainingArguments ===\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=15,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    ")\n",
    "\n",
    "# === 9. Trainer ===\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# === 10. Train ===\n",
    "trainer.train()\n",
    "\n",
    "print(\"Training complete\")\n",
    "\n",
    "print(\"Evaluating on test set\")\n",
    "# === 11. Evaluate on test set ===\n",
    "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "test_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
