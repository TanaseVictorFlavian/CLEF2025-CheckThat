{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03451961",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0615 18:59:50.296000 26588 Lib\\site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "os.chdir(\"../..\")\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq, AutoModelForSequenceClassification\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from task1.config import ProjectPaths\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "paths = ProjectPaths()\n",
    "\n",
    "# === 3. Set device ===\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# === 4. Load and preprocess data ===\n",
    "def load_dataset(path):\n",
    "    df = pd.read_csv(path, sep='\\t')\n",
    "    df = df[df['label'].isin(['SUBJ', 'OBJ'])].copy()\n",
    "    df['label'] = df['label'].map({'OBJ': 0, 'SUBJ': 1})\n",
    "    df = df[['sentence', 'label']]\n",
    "    return Dataset.from_pandas(df)\n",
    "\n",
    "train_dataset = load_dataset(paths.arabic_data_dir / \"train_ar.tsv\")\n",
    "val_dataset   = load_dataset(paths.arabic_data_dir / \"dev_ar.tsv\")\n",
    "test_dataset  = load_dataset(paths.arabic_data_dir / \"dev_test_ar.tsv\")\n",
    "competition_test_dataset = load_dataset(paths.arabic_data_dir / \"test_ar_labeled.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ece4cdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b49a43c3d5444ebe1ad72876475322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2446 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24cbebdaf08f42ef888a1e46d706d50b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25105c285648479abd0e4cdb7f9afd38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/748 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6934efdd35476395f588c15d0665b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1036 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === 5. Tokenization ===\n",
    "model_name = \"CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_fn(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"sentence\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_fn, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_fn, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_fn, batched=True)\n",
    "competition_test_dataset = competition_test_dataset.map(tokenize_fn, batched=True)\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
    "val_dataset = val_dataset.rename_column(\"label\", \"labels\")\n",
    "test_dataset = test_dataset.rename_column(\"label\", \"labels\")\n",
    "competition_test_dataset = competition_test_dataset.rename_column(\"label\", \"labels\")\n",
    "\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "competition_test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28460157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 7. Define metrics ===\n",
    "f1 = evaluate.load(\"f1\")\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1_macro\": f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
    "        \"precision\": precision.compute(predictions=preds, references=labels, average=\"macro\")[\"precision\"],\n",
    "        \"recall\": recall.compute(predictions=preds, references=labels, average=\"macro\")[\"recall\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2e1b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# === 6. Load model and add LoRA ===\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, ignore_mismatched_sizes=True )\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    target_modules=[\"query\", \"key\", \"value\"]  \n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config).to(device)\n",
    "\n",
    "\n",
    "# === 8. TrainingArguments ===\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results/arabic_lora\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5adf2170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca619631427c452baaa8f34778a3a15c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7509, 'grad_norm': 3.164447069168091, 'learning_rate': 4.991830065359477e-05, 'epoch': 0.02}\n",
      "{'loss': 0.6906, 'grad_norm': 4.1256327629089355, 'learning_rate': 4.983660130718955e-05, 'epoch': 0.03}\n",
      "{'loss': 0.7275, 'grad_norm': 5.46102237701416, 'learning_rate': 4.975490196078432e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7454, 'grad_norm': 5.023782253265381, 'learning_rate': 4.967320261437909e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6569, 'grad_norm': 8.242788314819336, 'learning_rate': 4.959150326797386e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7101, 'grad_norm': 4.897618770599365, 'learning_rate': 4.9509803921568634e-05, 'epoch': 0.1}\n",
      "{'loss': 0.7061, 'grad_norm': 3.834735155105591, 'learning_rate': 4.9428104575163404e-05, 'epoch': 0.11}\n",
      "{'loss': 0.7137, 'grad_norm': 7.145719051361084, 'learning_rate': 4.9346405228758174e-05, 'epoch': 0.13}\n",
      "{'loss': 0.6853, 'grad_norm': 3.5212061405181885, 'learning_rate': 4.9264705882352944e-05, 'epoch': 0.15}\n",
      "{'loss': 0.6901, 'grad_norm': 3.950662851333618, 'learning_rate': 4.918300653594771e-05, 'epoch': 0.16}\n",
      "{'loss': 0.7185, 'grad_norm': 5.7175116539001465, 'learning_rate': 4.910130718954248e-05, 'epoch': 0.18}\n",
      "{'loss': 0.7059, 'grad_norm': 6.895612716674805, 'learning_rate': 4.901960784313725e-05, 'epoch': 0.2}\n",
      "{'loss': 0.6997, 'grad_norm': 7.22767448425293, 'learning_rate': 4.893790849673203e-05, 'epoch': 0.21}\n",
      "{'loss': 0.6926, 'grad_norm': 4.922156810760498, 'learning_rate': 4.88562091503268e-05, 'epoch': 0.23}\n",
      "{'loss': 0.6912, 'grad_norm': 5.126274108886719, 'learning_rate': 4.877450980392157e-05, 'epoch': 0.25}\n",
      "{'loss': 0.7554, 'grad_norm': 3.401991605758667, 'learning_rate': 4.869281045751634e-05, 'epoch': 0.26}\n",
      "{'loss': 0.7016, 'grad_norm': 6.9778032302856445, 'learning_rate': 4.8611111111111115e-05, 'epoch': 0.28}\n",
      "{'loss': 0.6825, 'grad_norm': 7.905780792236328, 'learning_rate': 4.8529411764705885e-05, 'epoch': 0.29}\n",
      "{'loss': 0.7091, 'grad_norm': 6.16165018081665, 'learning_rate': 4.8447712418300655e-05, 'epoch': 0.31}\n",
      "{'loss': 0.7135, 'grad_norm': 5.1569132804870605, 'learning_rate': 4.8366013071895424e-05, 'epoch': 0.33}\n",
      "{'loss': 0.7336, 'grad_norm': 5.9919657707214355, 'learning_rate': 4.82843137254902e-05, 'epoch': 0.34}\n",
      "{'loss': 0.6822, 'grad_norm': 5.961860656738281, 'learning_rate': 4.820261437908497e-05, 'epoch': 0.36}\n",
      "{'loss': 0.6688, 'grad_norm': 2.490504741668701, 'learning_rate': 4.812091503267974e-05, 'epoch': 0.38}\n",
      "{'loss': 0.6603, 'grad_norm': 4.870344638824463, 'learning_rate': 4.803921568627452e-05, 'epoch': 0.39}\n",
      "{'loss': 0.6849, 'grad_norm': 2.446878671646118, 'learning_rate': 4.795751633986929e-05, 'epoch': 0.41}\n",
      "{'loss': 0.6555, 'grad_norm': 4.6361775398254395, 'learning_rate': 4.7875816993464056e-05, 'epoch': 0.42}\n",
      "{'loss': 0.6872, 'grad_norm': 5.411311149597168, 'learning_rate': 4.7794117647058826e-05, 'epoch': 0.44}\n",
      "{'loss': 0.6652, 'grad_norm': 5.2453389167785645, 'learning_rate': 4.77124183006536e-05, 'epoch': 0.46}\n",
      "{'loss': 0.7074, 'grad_norm': 10.25344467163086, 'learning_rate': 4.7630718954248366e-05, 'epoch': 0.47}\n",
      "{'loss': 0.6898, 'grad_norm': 7.037725448608398, 'learning_rate': 4.7549019607843135e-05, 'epoch': 0.49}\n",
      "{'loss': 0.6147, 'grad_norm': 4.248170852661133, 'learning_rate': 4.746732026143791e-05, 'epoch': 0.51}\n",
      "{'loss': 0.6911, 'grad_norm': 5.412473678588867, 'learning_rate': 4.738562091503268e-05, 'epoch': 0.52}\n",
      "{'loss': 0.6368, 'grad_norm': 2.82122540473938, 'learning_rate': 4.730392156862745e-05, 'epoch': 0.54}\n",
      "{'loss': 0.6595, 'grad_norm': 3.2792954444885254, 'learning_rate': 4.722222222222222e-05, 'epoch': 0.56}\n",
      "{'loss': 0.713, 'grad_norm': 7.752285480499268, 'learning_rate': 4.7140522875817e-05, 'epoch': 0.57}\n",
      "{'loss': 0.7345, 'grad_norm': 5.598280429840088, 'learning_rate': 4.705882352941177e-05, 'epoch': 0.59}\n",
      "{'loss': 0.6538, 'grad_norm': 4.4906415939331055, 'learning_rate': 4.697712418300654e-05, 'epoch': 0.6}\n",
      "{'loss': 0.6577, 'grad_norm': 8.431526184082031, 'learning_rate': 4.689542483660131e-05, 'epoch': 0.62}\n",
      "{'loss': 0.6687, 'grad_norm': 5.163338661193848, 'learning_rate': 4.681372549019608e-05, 'epoch': 0.64}\n",
      "{'loss': 0.7033, 'grad_norm': 4.453928470611572, 'learning_rate': 4.673202614379085e-05, 'epoch': 0.65}\n",
      "{'loss': 0.7215, 'grad_norm': 3.916125535964966, 'learning_rate': 4.665032679738562e-05, 'epoch': 0.67}\n",
      "{'loss': 0.6715, 'grad_norm': 4.093145847320557, 'learning_rate': 4.656862745098039e-05, 'epoch': 0.69}\n",
      "{'loss': 0.697, 'grad_norm': 5.410353183746338, 'learning_rate': 4.648692810457517e-05, 'epoch': 0.7}\n",
      "{'loss': 0.7081, 'grad_norm': 3.003826141357422, 'learning_rate': 4.640522875816994e-05, 'epoch': 0.72}\n",
      "{'loss': 0.6696, 'grad_norm': 7.2159905433654785, 'learning_rate': 4.632352941176471e-05, 'epoch': 0.74}\n",
      "{'loss': 0.7365, 'grad_norm': 3.984968900680542, 'learning_rate': 4.624183006535948e-05, 'epoch': 0.75}\n",
      "{'loss': 0.6738, 'grad_norm': 6.348816871643066, 'learning_rate': 4.6160130718954255e-05, 'epoch': 0.77}\n",
      "{'loss': 0.6908, 'grad_norm': 3.9880714416503906, 'learning_rate': 4.607843137254902e-05, 'epoch': 0.78}\n",
      "{'loss': 0.6633, 'grad_norm': 6.505917549133301, 'learning_rate': 4.599673202614379e-05, 'epoch': 0.8}\n",
      "{'loss': 0.6669, 'grad_norm': 3.543537139892578, 'learning_rate': 4.5915032679738564e-05, 'epoch': 0.82}\n",
      "{'loss': 0.7443, 'grad_norm': 3.835393190383911, 'learning_rate': 4.5833333333333334e-05, 'epoch': 0.83}\n",
      "{'loss': 0.6674, 'grad_norm': 4.851221561431885, 'learning_rate': 4.5751633986928104e-05, 'epoch': 0.85}\n",
      "{'loss': 0.7467, 'grad_norm': 3.8043439388275146, 'learning_rate': 4.566993464052288e-05, 'epoch': 0.87}\n",
      "{'loss': 0.6453, 'grad_norm': 7.5717082023620605, 'learning_rate': 4.558823529411765e-05, 'epoch': 0.88}\n",
      "{'loss': 0.6867, 'grad_norm': 3.7148499488830566, 'learning_rate': 4.550653594771242e-05, 'epoch': 0.9}\n",
      "{'loss': 0.6693, 'grad_norm': 5.658507347106934, 'learning_rate': 4.542483660130719e-05, 'epoch': 0.92}\n",
      "{'loss': 0.7265, 'grad_norm': 6.930824279785156, 'learning_rate': 4.5343137254901966e-05, 'epoch': 0.93}\n",
      "{'loss': 0.6466, 'grad_norm': 3.883171558380127, 'learning_rate': 4.5261437908496736e-05, 'epoch': 0.95}\n",
      "{'loss': 0.693, 'grad_norm': 4.6544413566589355, 'learning_rate': 4.5179738562091505e-05, 'epoch': 0.96}\n",
      "{'loss': 0.7222, 'grad_norm': 5.988192558288574, 'learning_rate': 4.5098039215686275e-05, 'epoch': 0.98}\n",
      "{'loss': 0.6798, 'grad_norm': 5.474152565002441, 'learning_rate': 4.501633986928105e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673da5a223334f998369aa2c0d60a4d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6790615320205688, 'eval_accuracy': 0.5546038543897216, 'eval_f1_macro': 0.43761000463177396, 'eval_precision': 0.5020052866648437, 'eval_recall': 0.5008229529046496, 'eval_runtime': 21.3759, 'eval_samples_per_second': 21.847, 'eval_steps_per_second': 5.473, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\peft\\utils\\other.py:611: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 8363dc70-fd0f-4a04-9de3-8fda495ec1bb)') - silently ignoring the lookup for the file config.json in CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment.\n",
      "  warnings.warn(\n",
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7051, 'grad_norm': 5.968447208404541, 'learning_rate': 4.493464052287582e-05, 'epoch': 1.01}\n",
      "{'loss': 0.6874, 'grad_norm': 4.307218074798584, 'learning_rate': 4.485294117647059e-05, 'epoch': 1.03}\n",
      "{'loss': 0.6725, 'grad_norm': 4.584897041320801, 'learning_rate': 4.477124183006536e-05, 'epoch': 1.05}\n",
      "{'loss': 0.6899, 'grad_norm': 4.60283899307251, 'learning_rate': 4.468954248366014e-05, 'epoch': 1.06}\n",
      "{'loss': 0.6198, 'grad_norm': 8.168156623840332, 'learning_rate': 4.460784313725491e-05, 'epoch': 1.08}\n",
      "{'loss': 0.7014, 'grad_norm': 7.459867000579834, 'learning_rate': 4.452614379084967e-05, 'epoch': 1.09}\n",
      "{'loss': 0.7086, 'grad_norm': 7.400516986846924, 'learning_rate': 4.4444444444444447e-05, 'epoch': 1.11}\n",
      "{'loss': 0.6379, 'grad_norm': 4.418552875518799, 'learning_rate': 4.4362745098039216e-05, 'epoch': 1.13}\n",
      "{'loss': 0.6621, 'grad_norm': 7.265684127807617, 'learning_rate': 4.4281045751633986e-05, 'epoch': 1.14}\n",
      "{'loss': 0.7312, 'grad_norm': 3.205720901489258, 'learning_rate': 4.4199346405228756e-05, 'epoch': 1.16}\n",
      "{'loss': 0.6362, 'grad_norm': 5.040136814117432, 'learning_rate': 4.411764705882353e-05, 'epoch': 1.18}\n",
      "{'loss': 0.6816, 'grad_norm': 3.3155086040496826, 'learning_rate': 4.40359477124183e-05, 'epoch': 1.19}\n",
      "{'loss': 0.727, 'grad_norm': 3.635751485824585, 'learning_rate': 4.395424836601307e-05, 'epoch': 1.21}\n",
      "{'loss': 0.6696, 'grad_norm': 4.958932876586914, 'learning_rate': 4.387254901960784e-05, 'epoch': 1.23}\n",
      "{'loss': 0.6938, 'grad_norm': 5.0578932762146, 'learning_rate': 4.379084967320262e-05, 'epoch': 1.24}\n",
      "{'loss': 0.7339, 'grad_norm': 6.691905975341797, 'learning_rate': 4.370915032679739e-05, 'epoch': 1.26}\n",
      "{'loss': 0.7, 'grad_norm': 4.108112812042236, 'learning_rate': 4.362745098039216e-05, 'epoch': 1.27}\n",
      "{'loss': 0.6787, 'grad_norm': 5.45736837387085, 'learning_rate': 4.3545751633986934e-05, 'epoch': 1.29}\n",
      "{'loss': 0.6835, 'grad_norm': 4.44791316986084, 'learning_rate': 4.3464052287581704e-05, 'epoch': 1.31}\n",
      "{'loss': 0.6689, 'grad_norm': 4.976698398590088, 'learning_rate': 4.3382352941176474e-05, 'epoch': 1.32}\n",
      "{'loss': 0.664, 'grad_norm': 3.125410556793213, 'learning_rate': 4.330065359477124e-05, 'epoch': 1.34}\n",
      "{'loss': 0.6958, 'grad_norm': 2.4820291996002197, 'learning_rate': 4.321895424836602e-05, 'epoch': 1.36}\n",
      "{'loss': 0.6635, 'grad_norm': 5.304713726043701, 'learning_rate': 4.313725490196079e-05, 'epoch': 1.37}\n",
      "{'loss': 0.7043, 'grad_norm': 3.4311938285827637, 'learning_rate': 4.305555555555556e-05, 'epoch': 1.39}\n",
      "{'loss': 0.6279, 'grad_norm': 3.529954671859741, 'learning_rate': 4.297385620915033e-05, 'epoch': 1.41}\n",
      "{'loss': 0.6402, 'grad_norm': 3.492279052734375, 'learning_rate': 4.28921568627451e-05, 'epoch': 1.42}\n",
      "{'loss': 0.7522, 'grad_norm': 7.941749095916748, 'learning_rate': 4.281045751633987e-05, 'epoch': 1.44}\n",
      "{'loss': 0.6959, 'grad_norm': 4.127070426940918, 'learning_rate': 4.272875816993464e-05, 'epoch': 1.45}\n",
      "{'loss': 0.6972, 'grad_norm': 8.232186317443848, 'learning_rate': 4.2647058823529415e-05, 'epoch': 1.47}\n",
      "{'loss': 0.6985, 'grad_norm': 2.7825374603271484, 'learning_rate': 4.2565359477124185e-05, 'epoch': 1.49}\n",
      "{'loss': 0.6725, 'grad_norm': 3.844512939453125, 'learning_rate': 4.2483660130718954e-05, 'epoch': 1.5}\n",
      "{'loss': 0.695, 'grad_norm': 4.646393299102783, 'learning_rate': 4.2401960784313724e-05, 'epoch': 1.52}\n",
      "{'loss': 0.7109, 'grad_norm': 3.185586452484131, 'learning_rate': 4.23202614379085e-05, 'epoch': 1.54}\n",
      "{'loss': 0.5982, 'grad_norm': 4.897818565368652, 'learning_rate': 4.223856209150327e-05, 'epoch': 1.55}\n",
      "{'loss': 0.6927, 'grad_norm': 5.237950801849365, 'learning_rate': 4.215686274509804e-05, 'epoch': 1.57}\n",
      "{'loss': 0.6648, 'grad_norm': 3.761932611465454, 'learning_rate': 4.207516339869281e-05, 'epoch': 1.58}\n",
      "{'loss': 0.7363, 'grad_norm': 5.659184455871582, 'learning_rate': 4.1993464052287586e-05, 'epoch': 1.6}\n",
      "{'loss': 0.684, 'grad_norm': 3.104152202606201, 'learning_rate': 4.1911764705882356e-05, 'epoch': 1.62}\n",
      "{'loss': 0.6892, 'grad_norm': 6.441634178161621, 'learning_rate': 4.1830065359477126e-05, 'epoch': 1.63}\n",
      "{'loss': 0.6873, 'grad_norm': 6.551194190979004, 'learning_rate': 4.17483660130719e-05, 'epoch': 1.65}\n",
      "{'loss': 0.6648, 'grad_norm': 4.2158203125, 'learning_rate': 4.166666666666667e-05, 'epoch': 1.67}\n",
      "{'loss': 0.6745, 'grad_norm': 6.956194877624512, 'learning_rate': 4.158496732026144e-05, 'epoch': 1.68}\n",
      "{'loss': 0.6673, 'grad_norm': 4.453457355499268, 'learning_rate': 4.150326797385621e-05, 'epoch': 1.7}\n",
      "{'loss': 0.6363, 'grad_norm': 6.1314520835876465, 'learning_rate': 4.142156862745099e-05, 'epoch': 1.72}\n",
      "{'loss': 0.6036, 'grad_norm': 4.425487518310547, 'learning_rate': 4.133986928104575e-05, 'epoch': 1.73}\n",
      "{'loss': 0.674, 'grad_norm': 6.4854841232299805, 'learning_rate': 4.125816993464052e-05, 'epoch': 1.75}\n",
      "{'loss': 0.5928, 'grad_norm': 4.386565685272217, 'learning_rate': 4.11764705882353e-05, 'epoch': 1.76}\n",
      "{'loss': 0.7207, 'grad_norm': 3.1943767070770264, 'learning_rate': 4.109477124183007e-05, 'epoch': 1.78}\n",
      "{'loss': 0.6487, 'grad_norm': 5.723285675048828, 'learning_rate': 4.101307189542484e-05, 'epoch': 1.8}\n",
      "{'loss': 0.6488, 'grad_norm': 6.328412055969238, 'learning_rate': 4.0931372549019607e-05, 'epoch': 1.81}\n",
      "{'loss': 0.7003, 'grad_norm': 6.683732032775879, 'learning_rate': 4.084967320261438e-05, 'epoch': 1.83}\n",
      "{'loss': 0.7417, 'grad_norm': 7.310545921325684, 'learning_rate': 4.076797385620915e-05, 'epoch': 1.85}\n",
      "{'loss': 0.6823, 'grad_norm': 3.594104290008545, 'learning_rate': 4.068627450980392e-05, 'epoch': 1.86}\n",
      "{'loss': 0.5972, 'grad_norm': 3.0078275203704834, 'learning_rate': 4.060457516339869e-05, 'epoch': 1.88}\n",
      "{'loss': 0.696, 'grad_norm': 5.270220756530762, 'learning_rate': 4.052287581699347e-05, 'epoch': 1.9}\n",
      "{'loss': 0.6955, 'grad_norm': 6.54518985748291, 'learning_rate': 4.044117647058824e-05, 'epoch': 1.91}\n",
      "{'loss': 0.6711, 'grad_norm': 2.691781997680664, 'learning_rate': 4.035947712418301e-05, 'epoch': 1.93}\n",
      "{'loss': 0.6077, 'grad_norm': 3.633788824081421, 'learning_rate': 4.027777777777778e-05, 'epoch': 1.94}\n",
      "{'loss': 0.712, 'grad_norm': 4.1169304847717285, 'learning_rate': 4.0196078431372555e-05, 'epoch': 1.96}\n",
      "{'loss': 0.6623, 'grad_norm': 4.723904609680176, 'learning_rate': 4.0114379084967324e-05, 'epoch': 1.98}\n",
      "{'loss': 0.6653, 'grad_norm': 3.6607086658477783, 'learning_rate': 4.0032679738562094e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "781591c24b734c91aa99721b11d09106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6807137727737427, 'eval_accuracy': 0.5674518201284796, 'eval_f1_macro': 0.4738174921909861, 'eval_precision': 0.5365778166193286, 'eval_recall': 0.5187876407436502, 'eval_runtime': 21.0262, 'eval_samples_per_second': 22.21, 'eval_steps_per_second': 5.564, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6778, 'grad_norm': 7.523370742797852, 'learning_rate': 3.9950980392156864e-05, 'epoch': 2.01}\n",
      "{'loss': 0.7227, 'grad_norm': 8.627387046813965, 'learning_rate': 3.986928104575164e-05, 'epoch': 2.03}\n",
      "{'loss': 0.6867, 'grad_norm': 2.6529695987701416, 'learning_rate': 3.97875816993464e-05, 'epoch': 2.04}\n",
      "{'loss': 0.7021, 'grad_norm': 4.787527084350586, 'learning_rate': 3.970588235294117e-05, 'epoch': 2.06}\n",
      "{'loss': 0.6774, 'grad_norm': 3.0096983909606934, 'learning_rate': 3.962418300653595e-05, 'epoch': 2.08}\n",
      "{'loss': 0.6382, 'grad_norm': 6.428757667541504, 'learning_rate': 3.954248366013072e-05, 'epoch': 2.09}\n",
      "{'loss': 0.6906, 'grad_norm': 4.863439083099365, 'learning_rate': 3.946078431372549e-05, 'epoch': 2.11}\n",
      "{'loss': 0.7138, 'grad_norm': 5.079254627227783, 'learning_rate': 3.9379084967320266e-05, 'epoch': 2.12}\n",
      "{'loss': 0.7819, 'grad_norm': 4.813907623291016, 'learning_rate': 3.9297385620915035e-05, 'epoch': 2.14}\n",
      "{'loss': 0.6727, 'grad_norm': 7.999652862548828, 'learning_rate': 3.9215686274509805e-05, 'epoch': 2.16}\n",
      "{'loss': 0.6586, 'grad_norm': 6.599490642547607, 'learning_rate': 3.9133986928104575e-05, 'epoch': 2.17}\n",
      "{'loss': 0.6771, 'grad_norm': 3.9838502407073975, 'learning_rate': 3.905228758169935e-05, 'epoch': 2.19}\n",
      "{'loss': 0.6734, 'grad_norm': 3.979191541671753, 'learning_rate': 3.897058823529412e-05, 'epoch': 2.21}\n",
      "{'loss': 0.6908, 'grad_norm': 4.056053638458252, 'learning_rate': 3.888888888888889e-05, 'epoch': 2.22}\n",
      "{'loss': 0.618, 'grad_norm': 5.402223587036133, 'learning_rate': 3.880718954248366e-05, 'epoch': 2.24}\n",
      "{'loss': 0.677, 'grad_norm': 4.264652252197266, 'learning_rate': 3.872549019607844e-05, 'epoch': 2.25}\n",
      "{'loss': 0.6365, 'grad_norm': 6.272465229034424, 'learning_rate': 3.864379084967321e-05, 'epoch': 2.27}\n",
      "{'loss': 0.7637, 'grad_norm': 4.984921455383301, 'learning_rate': 3.8562091503267977e-05, 'epoch': 2.29}\n",
      "{'loss': 0.602, 'grad_norm': 4.982294082641602, 'learning_rate': 3.8480392156862746e-05, 'epoch': 2.3}\n",
      "{'loss': 0.632, 'grad_norm': 4.164041519165039, 'learning_rate': 3.839869281045752e-05, 'epoch': 2.32}\n",
      "{'loss': 0.6745, 'grad_norm': 5.269476413726807, 'learning_rate': 3.831699346405229e-05, 'epoch': 2.34}\n",
      "{'loss': 0.7157, 'grad_norm': 8.252284049987793, 'learning_rate': 3.8235294117647055e-05, 'epoch': 2.35}\n",
      "{'loss': 0.659, 'grad_norm': 7.782069683074951, 'learning_rate': 3.815359477124183e-05, 'epoch': 2.37}\n",
      "{'loss': 0.6624, 'grad_norm': 6.62375020980835, 'learning_rate': 3.80718954248366e-05, 'epoch': 2.39}\n",
      "{'loss': 0.621, 'grad_norm': 4.773993492126465, 'learning_rate': 3.799019607843137e-05, 'epoch': 2.4}\n",
      "{'loss': 0.6473, 'grad_norm': 7.308971405029297, 'learning_rate': 3.790849673202614e-05, 'epoch': 2.42}\n",
      "{'loss': 0.6194, 'grad_norm': 7.323871612548828, 'learning_rate': 3.782679738562092e-05, 'epoch': 2.43}\n",
      "{'loss': 0.6447, 'grad_norm': 4.281777381896973, 'learning_rate': 3.774509803921569e-05, 'epoch': 2.45}\n",
      "{'loss': 0.6047, 'grad_norm': 5.259092807769775, 'learning_rate': 3.766339869281046e-05, 'epoch': 2.47}\n",
      "{'loss': 0.6757, 'grad_norm': 5.730136394500732, 'learning_rate': 3.758169934640523e-05, 'epoch': 2.48}\n",
      "{'loss': 0.7477, 'grad_norm': 4.164181709289551, 'learning_rate': 3.7500000000000003e-05, 'epoch': 2.5}\n",
      "{'loss': 0.7178, 'grad_norm': 4.869183540344238, 'learning_rate': 3.741830065359477e-05, 'epoch': 2.52}\n",
      "{'loss': 0.6517, 'grad_norm': 2.713986396789551, 'learning_rate': 3.733660130718954e-05, 'epoch': 2.53}\n",
      "{'loss': 0.6594, 'grad_norm': 3.0128955841064453, 'learning_rate': 3.725490196078432e-05, 'epoch': 2.55}\n",
      "{'loss': 0.7081, 'grad_norm': 4.960938453674316, 'learning_rate': 3.717320261437909e-05, 'epoch': 2.57}\n",
      "{'loss': 0.6733, 'grad_norm': 4.369100093841553, 'learning_rate': 3.709150326797386e-05, 'epoch': 2.58}\n",
      "{'loss': 0.6428, 'grad_norm': 6.4796576499938965, 'learning_rate': 3.700980392156863e-05, 'epoch': 2.6}\n",
      "{'loss': 0.5936, 'grad_norm': 4.049692153930664, 'learning_rate': 3.6928104575163405e-05, 'epoch': 2.61}\n",
      "{'loss': 0.7068, 'grad_norm': 7.928513526916504, 'learning_rate': 3.6846405228758175e-05, 'epoch': 2.63}\n",
      "{'loss': 0.6048, 'grad_norm': 4.49429178237915, 'learning_rate': 3.6764705882352945e-05, 'epoch': 2.65}\n",
      "{'loss': 0.647, 'grad_norm': 4.262774467468262, 'learning_rate': 3.6683006535947714e-05, 'epoch': 2.66}\n",
      "{'loss': 0.6582, 'grad_norm': 5.654110431671143, 'learning_rate': 3.6601307189542484e-05, 'epoch': 2.68}\n",
      "{'loss': 0.69, 'grad_norm': 4.490162372589111, 'learning_rate': 3.6519607843137254e-05, 'epoch': 2.7}\n",
      "{'loss': 0.6475, 'grad_norm': 2.8878633975982666, 'learning_rate': 3.6437908496732024e-05, 'epoch': 2.71}\n",
      "{'loss': 0.673, 'grad_norm': 3.598802089691162, 'learning_rate': 3.63562091503268e-05, 'epoch': 2.73}\n",
      "{'loss': 0.6556, 'grad_norm': 4.076930999755859, 'learning_rate': 3.627450980392157e-05, 'epoch': 2.75}\n",
      "{'loss': 0.5927, 'grad_norm': 4.820722579956055, 'learning_rate': 3.619281045751634e-05, 'epoch': 2.76}\n",
      "{'loss': 0.6497, 'grad_norm': 7.649962425231934, 'learning_rate': 3.611111111111111e-05, 'epoch': 2.78}\n",
      "{'loss': 0.6681, 'grad_norm': 4.8932905197143555, 'learning_rate': 3.6029411764705886e-05, 'epoch': 2.79}\n",
      "{'loss': 0.6756, 'grad_norm': 3.5183115005493164, 'learning_rate': 3.5947712418300656e-05, 'epoch': 2.81}\n",
      "{'loss': 0.696, 'grad_norm': 3.2271625995635986, 'learning_rate': 3.5866013071895425e-05, 'epoch': 2.83}\n",
      "{'loss': 0.6834, 'grad_norm': 4.529284954071045, 'learning_rate': 3.5784313725490195e-05, 'epoch': 2.84}\n",
      "{'loss': 0.7035, 'grad_norm': 6.558836460113525, 'learning_rate': 3.570261437908497e-05, 'epoch': 2.86}\n",
      "{'loss': 0.6965, 'grad_norm': 4.209047317504883, 'learning_rate': 3.562091503267974e-05, 'epoch': 2.88}\n",
      "{'loss': 0.6562, 'grad_norm': 3.598662853240967, 'learning_rate': 3.553921568627451e-05, 'epoch': 2.89}\n",
      "{'loss': 0.6381, 'grad_norm': 4.289705753326416, 'learning_rate': 3.545751633986929e-05, 'epoch': 2.91}\n",
      "{'loss': 0.6313, 'grad_norm': 2.82149076461792, 'learning_rate': 3.537581699346406e-05, 'epoch': 2.92}\n",
      "{'loss': 0.6858, 'grad_norm': 5.887591361999512, 'learning_rate': 3.529411764705883e-05, 'epoch': 2.94}\n",
      "{'loss': 0.7508, 'grad_norm': 5.638657569885254, 'learning_rate': 3.52124183006536e-05, 'epoch': 2.96}\n",
      "{'loss': 0.6331, 'grad_norm': 5.832512855529785, 'learning_rate': 3.513071895424837e-05, 'epoch': 2.97}\n",
      "{'loss': 0.6307, 'grad_norm': 5.152689456939697, 'learning_rate': 3.5049019607843136e-05, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124d18bd8463464ca06814c14649d8e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.693486750125885, 'eval_accuracy': 0.5653104925053534, 'eval_f1_macro': 0.4746499088405291, 'eval_precision': 0.5329289732770746, 'eval_recall': 0.5175158044364643, 'eval_runtime': 21.3432, 'eval_samples_per_second': 21.881, 'eval_steps_per_second': 5.482, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\peft\\utils\\other.py:611: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 63c4080b-a716-42ec-b054-3b3ff56a6651)') - silently ignoring the lookup for the file config.json in CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment.\n",
      "  warnings.warn(\n",
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5619, 'grad_norm': 5.293996334075928, 'learning_rate': 3.4967320261437906e-05, 'epoch': 3.01}\n",
      "{'loss': 0.6465, 'grad_norm': 6.7464189529418945, 'learning_rate': 3.488562091503268e-05, 'epoch': 3.02}\n",
      "{'loss': 0.7245, 'grad_norm': 9.954477310180664, 'learning_rate': 3.480392156862745e-05, 'epoch': 3.04}\n",
      "{'loss': 0.6452, 'grad_norm': 3.194906234741211, 'learning_rate': 3.472222222222222e-05, 'epoch': 3.06}\n",
      "{'loss': 0.699, 'grad_norm': 3.842905044555664, 'learning_rate': 3.464052287581699e-05, 'epoch': 3.07}\n",
      "{'loss': 0.7168, 'grad_norm': 7.275867938995361, 'learning_rate': 3.455882352941177e-05, 'epoch': 3.09}\n",
      "{'loss': 0.6152, 'grad_norm': 4.3054351806640625, 'learning_rate': 3.447712418300654e-05, 'epoch': 3.1}\n",
      "{'loss': 0.6595, 'grad_norm': 2.889285087585449, 'learning_rate': 3.439542483660131e-05, 'epoch': 3.12}\n",
      "{'loss': 0.6717, 'grad_norm': 6.458240985870361, 'learning_rate': 3.431372549019608e-05, 'epoch': 3.14}\n",
      "{'loss': 0.6536, 'grad_norm': 3.5540897846221924, 'learning_rate': 3.4232026143790854e-05, 'epoch': 3.15}\n",
      "{'loss': 0.6919, 'grad_norm': 8.903467178344727, 'learning_rate': 3.4150326797385624e-05, 'epoch': 3.17}\n",
      "{'loss': 0.6832, 'grad_norm': 6.210886001586914, 'learning_rate': 3.4068627450980394e-05, 'epoch': 3.19}\n",
      "{'loss': 0.5763, 'grad_norm': 4.122337818145752, 'learning_rate': 3.3986928104575163e-05, 'epoch': 3.2}\n",
      "{'loss': 0.6093, 'grad_norm': 4.7223310470581055, 'learning_rate': 3.390522875816994e-05, 'epoch': 3.22}\n",
      "{'loss': 0.6064, 'grad_norm': 5.303179740905762, 'learning_rate': 3.382352941176471e-05, 'epoch': 3.24}\n",
      "{'loss': 0.6638, 'grad_norm': 5.739376544952393, 'learning_rate': 3.374183006535948e-05, 'epoch': 3.25}\n",
      "{'loss': 0.6066, 'grad_norm': 5.032222270965576, 'learning_rate': 3.366013071895425e-05, 'epoch': 3.27}\n",
      "{'loss': 0.6766, 'grad_norm': 6.772529125213623, 'learning_rate': 3.357843137254902e-05, 'epoch': 3.28}\n",
      "{'loss': 0.6439, 'grad_norm': 4.129993438720703, 'learning_rate': 3.349673202614379e-05, 'epoch': 3.3}\n",
      "{'loss': 0.6766, 'grad_norm': 5.809318542480469, 'learning_rate': 3.341503267973856e-05, 'epoch': 3.32}\n",
      "{'loss': 0.6595, 'grad_norm': 10.816542625427246, 'learning_rate': 3.3333333333333335e-05, 'epoch': 3.33}\n",
      "{'loss': 0.6439, 'grad_norm': 5.168420314788818, 'learning_rate': 3.3251633986928105e-05, 'epoch': 3.35}\n",
      "{'loss': 0.6767, 'grad_norm': 7.102625846862793, 'learning_rate': 3.3169934640522874e-05, 'epoch': 3.37}\n",
      "{'loss': 0.6289, 'grad_norm': 3.816403865814209, 'learning_rate': 3.308823529411765e-05, 'epoch': 3.38}\n",
      "{'loss': 0.7935, 'grad_norm': 4.314029693603516, 'learning_rate': 3.300653594771242e-05, 'epoch': 3.4}\n",
      "{'loss': 0.667, 'grad_norm': 3.7723913192749023, 'learning_rate': 3.292483660130719e-05, 'epoch': 3.42}\n",
      "{'loss': 0.654, 'grad_norm': 3.2265877723693848, 'learning_rate': 3.284313725490196e-05, 'epoch': 3.43}\n",
      "{'loss': 0.685, 'grad_norm': 3.7216036319732666, 'learning_rate': 3.276143790849674e-05, 'epoch': 3.45}\n",
      "{'loss': 0.5952, 'grad_norm': 4.094024658203125, 'learning_rate': 3.2679738562091506e-05, 'epoch': 3.46}\n",
      "{'loss': 0.6983, 'grad_norm': 3.068943977355957, 'learning_rate': 3.2598039215686276e-05, 'epoch': 3.48}\n",
      "{'loss': 0.6498, 'grad_norm': 5.918277263641357, 'learning_rate': 3.2516339869281046e-05, 'epoch': 3.5}\n",
      "{'loss': 0.7534, 'grad_norm': 5.8522443771362305, 'learning_rate': 3.243464052287582e-05, 'epoch': 3.51}\n",
      "{'loss': 0.7758, 'grad_norm': 2.8023340702056885, 'learning_rate': 3.235294117647059e-05, 'epoch': 3.53}\n",
      "{'loss': 0.6459, 'grad_norm': 5.275411605834961, 'learning_rate': 3.227124183006536e-05, 'epoch': 3.55}\n",
      "{'loss': 0.7571, 'grad_norm': 4.599391937255859, 'learning_rate': 3.218954248366013e-05, 'epoch': 3.56}\n",
      "{'loss': 0.649, 'grad_norm': 3.310476779937744, 'learning_rate': 3.210784313725491e-05, 'epoch': 3.58}\n",
      "{'loss': 0.7088, 'grad_norm': 4.643462181091309, 'learning_rate': 3.202614379084967e-05, 'epoch': 3.59}\n",
      "{'loss': 0.6224, 'grad_norm': 5.433998107910156, 'learning_rate': 3.194444444444444e-05, 'epoch': 3.61}\n",
      "{'loss': 0.6082, 'grad_norm': 2.846649646759033, 'learning_rate': 3.186274509803922e-05, 'epoch': 3.63}\n",
      "{'loss': 0.5974, 'grad_norm': 4.44822359085083, 'learning_rate': 3.178104575163399e-05, 'epoch': 3.64}\n",
      "{'loss': 0.643, 'grad_norm': 7.449904918670654, 'learning_rate': 3.169934640522876e-05, 'epoch': 3.66}\n",
      "{'loss': 0.7365, 'grad_norm': 10.69757080078125, 'learning_rate': 3.161764705882353e-05, 'epoch': 3.68}\n",
      "{'loss': 0.6491, 'grad_norm': 4.174190998077393, 'learning_rate': 3.15359477124183e-05, 'epoch': 3.69}\n",
      "{'loss': 0.7085, 'grad_norm': 9.906907081604004, 'learning_rate': 3.145424836601307e-05, 'epoch': 3.71}\n",
      "{'loss': 0.7198, 'grad_norm': 5.8263325691223145, 'learning_rate': 3.137254901960784e-05, 'epoch': 3.73}\n",
      "{'loss': 0.6856, 'grad_norm': 5.086503028869629, 'learning_rate': 3.129084967320261e-05, 'epoch': 3.74}\n",
      "{'loss': 0.6387, 'grad_norm': 3.205322742462158, 'learning_rate': 3.120915032679739e-05, 'epoch': 3.76}\n",
      "{'loss': 0.6582, 'grad_norm': 5.936491012573242, 'learning_rate': 3.112745098039216e-05, 'epoch': 3.77}\n",
      "{'loss': 0.6101, 'grad_norm': 6.562388896942139, 'learning_rate': 3.104575163398693e-05, 'epoch': 3.79}\n",
      "{'loss': 0.6833, 'grad_norm': 4.6170454025268555, 'learning_rate': 3.0964052287581705e-05, 'epoch': 3.81}\n",
      "{'loss': 0.6597, 'grad_norm': 4.409311771392822, 'learning_rate': 3.0882352941176475e-05, 'epoch': 3.82}\n",
      "{'loss': 0.6334, 'grad_norm': 3.5376806259155273, 'learning_rate': 3.0800653594771244e-05, 'epoch': 3.84}\n",
      "{'loss': 0.6607, 'grad_norm': 2.768709897994995, 'learning_rate': 3.0718954248366014e-05, 'epoch': 3.86}\n",
      "{'loss': 0.7163, 'grad_norm': 3.957812786102295, 'learning_rate': 3.063725490196079e-05, 'epoch': 3.87}\n",
      "{'loss': 0.6264, 'grad_norm': 4.080292701721191, 'learning_rate': 3.055555555555556e-05, 'epoch': 3.89}\n",
      "{'loss': 0.6249, 'grad_norm': 7.450246810913086, 'learning_rate': 3.047385620915033e-05, 'epoch': 3.91}\n",
      "{'loss': 0.6054, 'grad_norm': 9.089433670043945, 'learning_rate': 3.0392156862745097e-05, 'epoch': 3.92}\n",
      "{'loss': 0.6839, 'grad_norm': 5.348578929901123, 'learning_rate': 3.031045751633987e-05, 'epoch': 3.94}\n",
      "{'loss': 0.6891, 'grad_norm': 4.814986228942871, 'learning_rate': 3.022875816993464e-05, 'epoch': 3.95}\n",
      "{'loss': 0.6627, 'grad_norm': 4.215300559997559, 'learning_rate': 3.0147058823529413e-05, 'epoch': 3.97}\n",
      "{'loss': 0.6347, 'grad_norm': 2.6942503452301025, 'learning_rate': 3.0065359477124182e-05, 'epoch': 3.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c755c3eccf9e4a419f259e93a7646aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6821533441543579, 'eval_accuracy': 0.5781584582441114, 'eval_f1_macro': 0.5595457526822519, 'eval_precision': 0.5639631610219845, 'eval_recall': 0.5604028728537762, 'eval_runtime': 21.5317, 'eval_samples_per_second': 21.689, 'eval_steps_per_second': 5.434, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6425, 'grad_norm': 3.6672627925872803, 'learning_rate': 2.9983660130718955e-05, 'epoch': 4.0}\n",
      "{'loss': 0.6453, 'grad_norm': 5.392911434173584, 'learning_rate': 2.9901960784313725e-05, 'epoch': 4.02}\n",
      "{'loss': 0.6198, 'grad_norm': 3.051546096801758, 'learning_rate': 2.9820261437908498e-05, 'epoch': 4.04}\n",
      "{'loss': 0.6464, 'grad_norm': 4.175714492797852, 'learning_rate': 2.9738562091503268e-05, 'epoch': 4.05}\n",
      "{'loss': 0.6556, 'grad_norm': 5.5802459716796875, 'learning_rate': 2.965686274509804e-05, 'epoch': 4.07}\n",
      "{'loss': 0.6627, 'grad_norm': 5.699153423309326, 'learning_rate': 2.957516339869281e-05, 'epoch': 4.08}\n",
      "{'loss': 0.6861, 'grad_norm': 3.7744593620300293, 'learning_rate': 2.9493464052287584e-05, 'epoch': 4.1}\n",
      "{'loss': 0.605, 'grad_norm': 3.8415467739105225, 'learning_rate': 2.9411764705882354e-05, 'epoch': 4.12}\n",
      "{'loss': 0.6036, 'grad_norm': 2.4305689334869385, 'learning_rate': 2.9330065359477127e-05, 'epoch': 4.13}\n",
      "{'loss': 0.5962, 'grad_norm': 3.036693572998047, 'learning_rate': 2.92483660130719e-05, 'epoch': 4.15}\n",
      "{'loss': 0.6896, 'grad_norm': 5.496719837188721, 'learning_rate': 2.916666666666667e-05, 'epoch': 4.17}\n",
      "{'loss': 0.6834, 'grad_norm': 3.4163129329681396, 'learning_rate': 2.9084967320261443e-05, 'epoch': 4.18}\n",
      "{'loss': 0.6375, 'grad_norm': 6.558139801025391, 'learning_rate': 2.9003267973856213e-05, 'epoch': 4.2}\n",
      "{'loss': 0.7643, 'grad_norm': 6.157371997833252, 'learning_rate': 2.8921568627450986e-05, 'epoch': 4.22}\n",
      "{'loss': 0.6108, 'grad_norm': 5.093454837799072, 'learning_rate': 2.8839869281045752e-05, 'epoch': 4.23}\n",
      "{'loss': 0.6718, 'grad_norm': 5.020463943481445, 'learning_rate': 2.8758169934640522e-05, 'epoch': 4.25}\n",
      "{'loss': 0.685, 'grad_norm': 9.36374568939209, 'learning_rate': 2.8676470588235295e-05, 'epoch': 4.26}\n",
      "{'loss': 0.6382, 'grad_norm': 6.038527488708496, 'learning_rate': 2.8594771241830065e-05, 'epoch': 4.28}\n",
      "{'loss': 0.5966, 'grad_norm': 3.599271535873413, 'learning_rate': 2.8513071895424838e-05, 'epoch': 4.3}\n",
      "{'loss': 0.663, 'grad_norm': 3.837161064147949, 'learning_rate': 2.8431372549019608e-05, 'epoch': 4.31}\n",
      "{'loss': 0.7738, 'grad_norm': 3.222714900970459, 'learning_rate': 2.834967320261438e-05, 'epoch': 4.33}\n",
      "{'loss': 0.6973, 'grad_norm': 5.337629318237305, 'learning_rate': 2.826797385620915e-05, 'epoch': 4.35}\n",
      "{'loss': 0.6235, 'grad_norm': 6.539713382720947, 'learning_rate': 2.8186274509803924e-05, 'epoch': 4.36}\n",
      "{'loss': 0.7587, 'grad_norm': 4.221185207366943, 'learning_rate': 2.8104575163398693e-05, 'epoch': 4.38}\n",
      "{'loss': 0.6625, 'grad_norm': 5.079559803009033, 'learning_rate': 2.8022875816993466e-05, 'epoch': 4.4}\n",
      "{'loss': 0.6599, 'grad_norm': 5.0972795486450195, 'learning_rate': 2.7941176470588236e-05, 'epoch': 4.41}\n",
      "{'loss': 0.6174, 'grad_norm': 3.810534715652466, 'learning_rate': 2.785947712418301e-05, 'epoch': 4.43}\n",
      "{'loss': 0.7155, 'grad_norm': 5.874232292175293, 'learning_rate': 2.777777777777778e-05, 'epoch': 4.44}\n",
      "{'loss': 0.6031, 'grad_norm': 4.917116641998291, 'learning_rate': 2.7696078431372552e-05, 'epoch': 4.46}\n",
      "{'loss': 0.6935, 'grad_norm': 6.691040992736816, 'learning_rate': 2.7614379084967322e-05, 'epoch': 4.48}\n",
      "{'loss': 0.6945, 'grad_norm': 3.905122995376587, 'learning_rate': 2.7532679738562095e-05, 'epoch': 4.49}\n",
      "{'loss': 0.7217, 'grad_norm': 5.071287631988525, 'learning_rate': 2.7450980392156865e-05, 'epoch': 4.51}\n",
      "{'loss': 0.6934, 'grad_norm': 8.364423751831055, 'learning_rate': 2.7369281045751638e-05, 'epoch': 4.53}\n",
      "{'loss': 0.6762, 'grad_norm': 5.538858413696289, 'learning_rate': 2.7287581699346404e-05, 'epoch': 4.54}\n",
      "{'loss': 0.59, 'grad_norm': 9.241840362548828, 'learning_rate': 2.7205882352941174e-05, 'epoch': 4.56}\n",
      "{'loss': 0.625, 'grad_norm': 3.3854196071624756, 'learning_rate': 2.7124183006535947e-05, 'epoch': 4.58}\n",
      "{'loss': 0.6132, 'grad_norm': 4.60871696472168, 'learning_rate': 2.7042483660130717e-05, 'epoch': 4.59}\n",
      "{'loss': 0.6186, 'grad_norm': 3.5694239139556885, 'learning_rate': 2.696078431372549e-05, 'epoch': 4.61}\n",
      "{'loss': 0.6936, 'grad_norm': 6.408876895904541, 'learning_rate': 2.6879084967320263e-05, 'epoch': 4.62}\n",
      "{'loss': 0.5796, 'grad_norm': 5.686847686767578, 'learning_rate': 2.6797385620915033e-05, 'epoch': 4.64}\n",
      "{'loss': 0.7106, 'grad_norm': 8.929930686950684, 'learning_rate': 2.6715686274509806e-05, 'epoch': 4.66}\n",
      "{'loss': 0.6145, 'grad_norm': 4.281318664550781, 'learning_rate': 2.6633986928104576e-05, 'epoch': 4.67}\n",
      "{'loss': 0.6233, 'grad_norm': 2.6703784465789795, 'learning_rate': 2.655228758169935e-05, 'epoch': 4.69}\n",
      "{'loss': 0.5854, 'grad_norm': 5.775902271270752, 'learning_rate': 2.647058823529412e-05, 'epoch': 4.71}\n",
      "{'loss': 0.7786, 'grad_norm': 3.660423755645752, 'learning_rate': 2.6388888888888892e-05, 'epoch': 4.72}\n",
      "{'loss': 0.7019, 'grad_norm': 3.0980300903320312, 'learning_rate': 2.630718954248366e-05, 'epoch': 4.74}\n",
      "{'loss': 0.6112, 'grad_norm': 6.913140773773193, 'learning_rate': 2.6225490196078435e-05, 'epoch': 4.75}\n",
      "{'loss': 0.6253, 'grad_norm': 3.4174442291259766, 'learning_rate': 2.6143790849673204e-05, 'epoch': 4.77}\n",
      "{'loss': 0.6795, 'grad_norm': 3.8389501571655273, 'learning_rate': 2.6062091503267978e-05, 'epoch': 4.79}\n",
      "{'loss': 0.7027, 'grad_norm': 4.353610515594482, 'learning_rate': 2.5980392156862747e-05, 'epoch': 4.8}\n",
      "{'loss': 0.618, 'grad_norm': 3.3575963973999023, 'learning_rate': 2.589869281045752e-05, 'epoch': 4.82}\n",
      "{'loss': 0.5933, 'grad_norm': 4.56741189956665, 'learning_rate': 2.581699346405229e-05, 'epoch': 4.84}\n",
      "{'loss': 0.6557, 'grad_norm': 6.0177435874938965, 'learning_rate': 2.5735294117647057e-05, 'epoch': 4.85}\n",
      "{'loss': 0.6474, 'grad_norm': 5.448533535003662, 'learning_rate': 2.565359477124183e-05, 'epoch': 4.87}\n",
      "{'loss': 0.7301, 'grad_norm': 6.683203220367432, 'learning_rate': 2.55718954248366e-05, 'epoch': 4.89}\n",
      "{'loss': 0.5724, 'grad_norm': 4.490822792053223, 'learning_rate': 2.5490196078431373e-05, 'epoch': 4.9}\n",
      "{'loss': 0.624, 'grad_norm': 4.381649494171143, 'learning_rate': 2.5408496732026142e-05, 'epoch': 4.92}\n",
      "{'loss': 0.6955, 'grad_norm': 6.438292980194092, 'learning_rate': 2.5326797385620915e-05, 'epoch': 4.93}\n",
      "{'loss': 0.6867, 'grad_norm': 4.713222026824951, 'learning_rate': 2.5245098039215685e-05, 'epoch': 4.95}\n",
      "{'loss': 0.6379, 'grad_norm': 3.8662099838256836, 'learning_rate': 2.516339869281046e-05, 'epoch': 4.97}\n",
      "{'loss': 0.7166, 'grad_norm': 3.7587883472442627, 'learning_rate': 2.5081699346405228e-05, 'epoch': 4.98}\n",
      "{'loss': 0.637, 'grad_norm': 6.429995536804199, 'learning_rate': 2.5e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609d5702678c4d04bcaf38f0c66938f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6951653361320496, 'eval_accuracy': 0.5674518201284796, 'eval_f1_macro': 0.5169493261234689, 'eval_precision': 0.5432806324110673, 'eval_recall': 0.5327684883851419, 'eval_runtime': 20.306, 'eval_samples_per_second': 22.998, 'eval_steps_per_second': 5.762, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\peft\\utils\\other.py:611: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 28235acc-d60b-4b01-9f15-6b7286270f72)') - silently ignoring the lookup for the file config.json in CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment.\n",
      "  warnings.warn(\n",
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7144, 'grad_norm': 6.309552192687988, 'learning_rate': 2.4918300653594774e-05, 'epoch': 5.02}\n",
      "{'loss': 0.5726, 'grad_norm': 5.911734104156494, 'learning_rate': 2.4836601307189544e-05, 'epoch': 5.03}\n",
      "{'loss': 0.594, 'grad_norm': 5.559919357299805, 'learning_rate': 2.4754901960784317e-05, 'epoch': 5.05}\n",
      "{'loss': 0.6987, 'grad_norm': 8.57082462310791, 'learning_rate': 2.4673202614379087e-05, 'epoch': 5.07}\n",
      "{'loss': 0.8372, 'grad_norm': 2.5112838745117188, 'learning_rate': 2.4591503267973857e-05, 'epoch': 5.08}\n",
      "{'loss': 0.7081, 'grad_norm': 3.4107468128204346, 'learning_rate': 2.4509803921568626e-05, 'epoch': 5.1}\n",
      "{'loss': 0.7661, 'grad_norm': 8.572282791137695, 'learning_rate': 2.44281045751634e-05, 'epoch': 5.11}\n",
      "{'loss': 0.6249, 'grad_norm': 5.360421657562256, 'learning_rate': 2.434640522875817e-05, 'epoch': 5.13}\n",
      "{'loss': 0.6494, 'grad_norm': 4.284732818603516, 'learning_rate': 2.4264705882352942e-05, 'epoch': 5.15}\n",
      "{'loss': 0.6185, 'grad_norm': 3.6587791442871094, 'learning_rate': 2.4183006535947712e-05, 'epoch': 5.16}\n",
      "{'loss': 0.6492, 'grad_norm': 6.15282678604126, 'learning_rate': 2.4101307189542485e-05, 'epoch': 5.18}\n",
      "{'loss': 0.6353, 'grad_norm': 4.21721887588501, 'learning_rate': 2.401960784313726e-05, 'epoch': 5.2}\n",
      "{'loss': 0.6586, 'grad_norm': 5.842411041259766, 'learning_rate': 2.3937908496732028e-05, 'epoch': 5.21}\n",
      "{'loss': 0.6365, 'grad_norm': 9.704680442810059, 'learning_rate': 2.38562091503268e-05, 'epoch': 5.23}\n",
      "{'loss': 0.559, 'grad_norm': 3.012890577316284, 'learning_rate': 2.3774509803921568e-05, 'epoch': 5.25}\n",
      "{'loss': 0.7769, 'grad_norm': 5.112237453460693, 'learning_rate': 2.369281045751634e-05, 'epoch': 5.26}\n",
      "{'loss': 0.5969, 'grad_norm': 3.5379347801208496, 'learning_rate': 2.361111111111111e-05, 'epoch': 5.28}\n",
      "{'loss': 0.7313, 'grad_norm': 4.901226997375488, 'learning_rate': 2.3529411764705884e-05, 'epoch': 5.29}\n",
      "{'loss': 0.6605, 'grad_norm': 6.932276725769043, 'learning_rate': 2.3447712418300653e-05, 'epoch': 5.31}\n",
      "{'loss': 0.7338, 'grad_norm': 11.285197257995605, 'learning_rate': 2.3366013071895427e-05, 'epoch': 5.33}\n",
      "{'loss': 0.6081, 'grad_norm': 3.6942315101623535, 'learning_rate': 2.3284313725490196e-05, 'epoch': 5.34}\n",
      "{'loss': 0.6351, 'grad_norm': 3.6577436923980713, 'learning_rate': 2.320261437908497e-05, 'epoch': 5.36}\n",
      "{'loss': 0.5518, 'grad_norm': 5.288631916046143, 'learning_rate': 2.312091503267974e-05, 'epoch': 5.38}\n",
      "{'loss': 0.633, 'grad_norm': 8.79922103881836, 'learning_rate': 2.303921568627451e-05, 'epoch': 5.39}\n",
      "{'loss': 0.6587, 'grad_norm': 3.6907477378845215, 'learning_rate': 2.2957516339869282e-05, 'epoch': 5.41}\n",
      "{'loss': 0.6789, 'grad_norm': 3.5262463092803955, 'learning_rate': 2.2875816993464052e-05, 'epoch': 5.42}\n",
      "{'loss': 0.7135, 'grad_norm': 4.174232006072998, 'learning_rate': 2.2794117647058825e-05, 'epoch': 5.44}\n",
      "{'loss': 0.7068, 'grad_norm': 4.63654899597168, 'learning_rate': 2.2712418300653595e-05, 'epoch': 5.46}\n",
      "{'loss': 0.5944, 'grad_norm': 4.864634990692139, 'learning_rate': 2.2630718954248368e-05, 'epoch': 5.47}\n",
      "{'loss': 0.5922, 'grad_norm': 3.6616404056549072, 'learning_rate': 2.2549019607843138e-05, 'epoch': 5.49}\n",
      "{'loss': 0.6992, 'grad_norm': 4.509215831756592, 'learning_rate': 2.246732026143791e-05, 'epoch': 5.51}\n",
      "{'loss': 0.6012, 'grad_norm': 3.8798890113830566, 'learning_rate': 2.238562091503268e-05, 'epoch': 5.52}\n",
      "{'loss': 0.7192, 'grad_norm': 3.548983097076416, 'learning_rate': 2.2303921568627454e-05, 'epoch': 5.54}\n",
      "{'loss': 0.6297, 'grad_norm': 3.722503423690796, 'learning_rate': 2.2222222222222223e-05, 'epoch': 5.56}\n",
      "{'loss': 0.6903, 'grad_norm': 6.461005687713623, 'learning_rate': 2.2140522875816993e-05, 'epoch': 5.57}\n",
      "{'loss': 0.6925, 'grad_norm': 3.820479393005371, 'learning_rate': 2.2058823529411766e-05, 'epoch': 5.59}\n",
      "{'loss': 0.6687, 'grad_norm': 5.406132698059082, 'learning_rate': 2.1977124183006536e-05, 'epoch': 5.6}\n",
      "{'loss': 0.7396, 'grad_norm': 4.162783145904541, 'learning_rate': 2.189542483660131e-05, 'epoch': 5.62}\n",
      "{'loss': 0.6444, 'grad_norm': 5.670657634735107, 'learning_rate': 2.181372549019608e-05, 'epoch': 5.64}\n",
      "{'loss': 0.5671, 'grad_norm': 5.0070600509643555, 'learning_rate': 2.1732026143790852e-05, 'epoch': 5.65}\n",
      "{'loss': 0.6762, 'grad_norm': 5.369486331939697, 'learning_rate': 2.165032679738562e-05, 'epoch': 5.67}\n",
      "{'loss': 0.5625, 'grad_norm': 3.4757802486419678, 'learning_rate': 2.1568627450980395e-05, 'epoch': 5.69}\n",
      "{'loss': 0.6325, 'grad_norm': 6.533054828643799, 'learning_rate': 2.1486928104575165e-05, 'epoch': 5.7}\n",
      "{'loss': 0.6886, 'grad_norm': 6.01867151260376, 'learning_rate': 2.1405228758169934e-05, 'epoch': 5.72}\n",
      "{'loss': 0.712, 'grad_norm': 2.8329057693481445, 'learning_rate': 2.1323529411764707e-05, 'epoch': 5.74}\n",
      "{'loss': 0.6533, 'grad_norm': 5.222355365753174, 'learning_rate': 2.1241830065359477e-05, 'epoch': 5.75}\n",
      "{'loss': 0.6004, 'grad_norm': 4.182484149932861, 'learning_rate': 2.116013071895425e-05, 'epoch': 5.77}\n",
      "{'loss': 0.6059, 'grad_norm': 4.553465843200684, 'learning_rate': 2.107843137254902e-05, 'epoch': 5.78}\n",
      "{'loss': 0.6766, 'grad_norm': 6.530998706817627, 'learning_rate': 2.0996732026143793e-05, 'epoch': 5.8}\n",
      "{'loss': 0.6404, 'grad_norm': 3.8326339721679688, 'learning_rate': 2.0915032679738563e-05, 'epoch': 5.82}\n",
      "{'loss': 0.6314, 'grad_norm': 4.604804992675781, 'learning_rate': 2.0833333333333336e-05, 'epoch': 5.83}\n",
      "{'loss': 0.612, 'grad_norm': 4.418515682220459, 'learning_rate': 2.0751633986928106e-05, 'epoch': 5.85}\n",
      "{'loss': 0.5959, 'grad_norm': 5.526870250701904, 'learning_rate': 2.0669934640522876e-05, 'epoch': 5.87}\n",
      "{'loss': 0.5963, 'grad_norm': 7.132465362548828, 'learning_rate': 2.058823529411765e-05, 'epoch': 5.88}\n",
      "{'loss': 0.5919, 'grad_norm': 5.274823188781738, 'learning_rate': 2.050653594771242e-05, 'epoch': 5.9}\n",
      "{'loss': 0.5808, 'grad_norm': 4.244053363800049, 'learning_rate': 2.042483660130719e-05, 'epoch': 5.92}\n",
      "{'loss': 0.6217, 'grad_norm': 7.537549018859863, 'learning_rate': 2.034313725490196e-05, 'epoch': 5.93}\n",
      "{'loss': 0.7108, 'grad_norm': 3.6383056640625, 'learning_rate': 2.0261437908496734e-05, 'epoch': 5.95}\n",
      "{'loss': 0.5211, 'grad_norm': 4.112098217010498, 'learning_rate': 2.0179738562091504e-05, 'epoch': 5.96}\n",
      "{'loss': 0.6213, 'grad_norm': 7.537527561187744, 'learning_rate': 2.0098039215686277e-05, 'epoch': 5.98}\n",
      "{'loss': 0.5994, 'grad_norm': 3.5389254093170166, 'learning_rate': 2.0016339869281047e-05, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189195cbf05e45b485bd4ccac2621e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6982872486114502, 'eval_accuracy': 0.588865096359743, 'eval_f1_macro': 0.55821836815136, 'eval_precision': 0.5728330311663645, 'eval_recall': 0.5631148767440991, 'eval_runtime': 21.4325, 'eval_samples_per_second': 21.789, 'eval_steps_per_second': 5.459, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6873, 'grad_norm': 2.3993728160858154, 'learning_rate': 1.993464052287582e-05, 'epoch': 6.01}\n",
      "{'loss': 0.663, 'grad_norm': 7.096456527709961, 'learning_rate': 1.9852941176470586e-05, 'epoch': 6.03}\n",
      "{'loss': 0.718, 'grad_norm': 8.997204780578613, 'learning_rate': 1.977124183006536e-05, 'epoch': 6.05}\n",
      "{'loss': 0.6888, 'grad_norm': 5.602980136871338, 'learning_rate': 1.9689542483660133e-05, 'epoch': 6.06}\n",
      "{'loss': 0.6231, 'grad_norm': 4.094402313232422, 'learning_rate': 1.9607843137254903e-05, 'epoch': 6.08}\n",
      "{'loss': 0.6525, 'grad_norm': 3.6936538219451904, 'learning_rate': 1.9526143790849676e-05, 'epoch': 6.09}\n",
      "{'loss': 0.6294, 'grad_norm': 4.135326385498047, 'learning_rate': 1.9444444444444445e-05, 'epoch': 6.11}\n",
      "{'loss': 0.6151, 'grad_norm': 3.9150164127349854, 'learning_rate': 1.936274509803922e-05, 'epoch': 6.13}\n",
      "{'loss': 0.6568, 'grad_norm': 6.210345268249512, 'learning_rate': 1.9281045751633988e-05, 'epoch': 6.14}\n",
      "{'loss': 0.63, 'grad_norm': 5.903650283813477, 'learning_rate': 1.919934640522876e-05, 'epoch': 6.16}\n",
      "{'loss': 0.6458, 'grad_norm': 10.336020469665527, 'learning_rate': 1.9117647058823528e-05, 'epoch': 6.18}\n",
      "{'loss': 0.6952, 'grad_norm': 4.014270782470703, 'learning_rate': 1.90359477124183e-05, 'epoch': 6.19}\n",
      "{'loss': 0.6591, 'grad_norm': 4.059529781341553, 'learning_rate': 1.895424836601307e-05, 'epoch': 6.21}\n",
      "{'loss': 0.6835, 'grad_norm': 7.661774635314941, 'learning_rate': 1.8872549019607844e-05, 'epoch': 6.23}\n",
      "{'loss': 0.6284, 'grad_norm': 5.66872501373291, 'learning_rate': 1.8790849673202613e-05, 'epoch': 6.24}\n",
      "{'loss': 0.5674, 'grad_norm': 8.76159381866455, 'learning_rate': 1.8709150326797387e-05, 'epoch': 6.26}\n",
      "{'loss': 0.5709, 'grad_norm': 4.196857452392578, 'learning_rate': 1.862745098039216e-05, 'epoch': 6.27}\n",
      "{'loss': 0.6125, 'grad_norm': 6.11309814453125, 'learning_rate': 1.854575163398693e-05, 'epoch': 6.29}\n",
      "{'loss': 0.6536, 'grad_norm': 6.840208053588867, 'learning_rate': 1.8464052287581703e-05, 'epoch': 6.31}\n",
      "{'loss': 0.7409, 'grad_norm': 7.11051607131958, 'learning_rate': 1.8382352941176472e-05, 'epoch': 6.32}\n",
      "{'loss': 0.576, 'grad_norm': 5.293100357055664, 'learning_rate': 1.8300653594771242e-05, 'epoch': 6.34}\n",
      "{'loss': 0.7144, 'grad_norm': 3.0477426052093506, 'learning_rate': 1.8218954248366012e-05, 'epoch': 6.36}\n",
      "{'loss': 0.5341, 'grad_norm': 4.184670925140381, 'learning_rate': 1.8137254901960785e-05, 'epoch': 6.37}\n",
      "{'loss': 0.6023, 'grad_norm': 4.887930870056152, 'learning_rate': 1.8055555555555555e-05, 'epoch': 6.39}\n",
      "{'loss': 0.6812, 'grad_norm': 4.852538108825684, 'learning_rate': 1.7973856209150328e-05, 'epoch': 6.41}\n",
      "{'loss': 0.58, 'grad_norm': 5.952986240386963, 'learning_rate': 1.7892156862745098e-05, 'epoch': 6.42}\n",
      "{'loss': 0.6642, 'grad_norm': 5.319510459899902, 'learning_rate': 1.781045751633987e-05, 'epoch': 6.44}\n",
      "{'loss': 0.6729, 'grad_norm': 7.571269989013672, 'learning_rate': 1.7728758169934644e-05, 'epoch': 6.45}\n",
      "{'loss': 0.5664, 'grad_norm': 6.002463340759277, 'learning_rate': 1.7647058823529414e-05, 'epoch': 6.47}\n",
      "{'loss': 0.7454, 'grad_norm': 4.253355979919434, 'learning_rate': 1.7565359477124183e-05, 'epoch': 6.49}\n",
      "{'loss': 0.6361, 'grad_norm': 3.879047155380249, 'learning_rate': 1.7483660130718953e-05, 'epoch': 6.5}\n",
      "{'loss': 0.5642, 'grad_norm': 3.478811264038086, 'learning_rate': 1.7401960784313726e-05, 'epoch': 6.52}\n",
      "{'loss': 0.7109, 'grad_norm': 4.07739782333374, 'learning_rate': 1.7320261437908496e-05, 'epoch': 6.54}\n",
      "{'loss': 0.6608, 'grad_norm': 5.509951114654541, 'learning_rate': 1.723856209150327e-05, 'epoch': 6.55}\n",
      "{'loss': 0.6112, 'grad_norm': 5.255852699279785, 'learning_rate': 1.715686274509804e-05, 'epoch': 6.57}\n",
      "{'loss': 0.6976, 'grad_norm': 5.078513145446777, 'learning_rate': 1.7075163398692812e-05, 'epoch': 6.58}\n",
      "{'loss': 0.6515, 'grad_norm': 2.9281749725341797, 'learning_rate': 1.6993464052287582e-05, 'epoch': 6.6}\n",
      "{'loss': 0.668, 'grad_norm': 4.008479118347168, 'learning_rate': 1.6911764705882355e-05, 'epoch': 6.62}\n",
      "{'loss': 0.608, 'grad_norm': 5.348876476287842, 'learning_rate': 1.6830065359477125e-05, 'epoch': 6.63}\n",
      "{'loss': 0.6216, 'grad_norm': 7.777538299560547, 'learning_rate': 1.6748366013071894e-05, 'epoch': 6.65}\n",
      "{'loss': 0.688, 'grad_norm': 3.877098560333252, 'learning_rate': 1.6666666666666667e-05, 'epoch': 6.67}\n",
      "{'loss': 0.5566, 'grad_norm': 5.921393394470215, 'learning_rate': 1.6584967320261437e-05, 'epoch': 6.68}\n",
      "{'loss': 0.5549, 'grad_norm': 3.8083674907684326, 'learning_rate': 1.650326797385621e-05, 'epoch': 6.7}\n",
      "{'loss': 0.721, 'grad_norm': 3.577021598815918, 'learning_rate': 1.642156862745098e-05, 'epoch': 6.72}\n",
      "{'loss': 0.7036, 'grad_norm': 3.4966306686401367, 'learning_rate': 1.6339869281045753e-05, 'epoch': 6.73}\n",
      "{'loss': 0.5635, 'grad_norm': 3.219255208969116, 'learning_rate': 1.6258169934640523e-05, 'epoch': 6.75}\n",
      "{'loss': 0.5391, 'grad_norm': 3.31189227104187, 'learning_rate': 1.6176470588235296e-05, 'epoch': 6.76}\n",
      "{'loss': 0.6309, 'grad_norm': 8.13238525390625, 'learning_rate': 1.6094771241830066e-05, 'epoch': 6.78}\n",
      "{'loss': 0.6584, 'grad_norm': 3.2663753032684326, 'learning_rate': 1.6013071895424836e-05, 'epoch': 6.8}\n",
      "{'loss': 0.6264, 'grad_norm': 5.555944442749023, 'learning_rate': 1.593137254901961e-05, 'epoch': 6.81}\n",
      "{'loss': 0.7081, 'grad_norm': 3.5197579860687256, 'learning_rate': 1.584967320261438e-05, 'epoch': 6.83}\n",
      "{'loss': 0.5656, 'grad_norm': 2.8052215576171875, 'learning_rate': 1.576797385620915e-05, 'epoch': 6.85}\n",
      "{'loss': 0.61, 'grad_norm': 4.771102428436279, 'learning_rate': 1.568627450980392e-05, 'epoch': 6.86}\n",
      "{'loss': 0.6536, 'grad_norm': 9.885302543640137, 'learning_rate': 1.5604575163398694e-05, 'epoch': 6.88}\n",
      "{'loss': 0.6866, 'grad_norm': 5.071754455566406, 'learning_rate': 1.5522875816993464e-05, 'epoch': 6.9}\n",
      "{'loss': 0.7002, 'grad_norm': 5.262521266937256, 'learning_rate': 1.5441176470588237e-05, 'epoch': 6.91}\n",
      "{'loss': 0.673, 'grad_norm': 7.1802778244018555, 'learning_rate': 1.5359477124183007e-05, 'epoch': 6.93}\n",
      "{'loss': 0.6663, 'grad_norm': 6.060202598571777, 'learning_rate': 1.527777777777778e-05, 'epoch': 6.94}\n",
      "{'loss': 0.6955, 'grad_norm': 4.170590400695801, 'learning_rate': 1.5196078431372548e-05, 'epoch': 6.96}\n",
      "{'loss': 0.6189, 'grad_norm': 6.407129764556885, 'learning_rate': 1.511437908496732e-05, 'epoch': 6.98}\n",
      "{'loss': 0.6433, 'grad_norm': 6.015446662902832, 'learning_rate': 1.5032679738562091e-05, 'epoch': 6.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1e58ad53fb494797f9a8c57fe93150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7021394968032837, 'eval_accuracy': 0.5802997858672377, 'eval_f1_macro': 0.565919265498141, 'eval_precision': 0.5680948885368775, 'eval_recall': 0.5659297497475031, 'eval_runtime': 20.5097, 'eval_samples_per_second': 22.77, 'eval_steps_per_second': 5.705, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\peft\\utils\\other.py:611: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: b830b3aa-634a-451d-bf3d-57b7a0b242e0)') - silently ignoring the lookup for the file config.json in CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment.\n",
      "  warnings.warn(\n",
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6804, 'grad_norm': 4.649173736572266, 'learning_rate': 1.4950980392156863e-05, 'epoch': 7.01}\n",
      "{'loss': 0.5993, 'grad_norm': 5.461357593536377, 'learning_rate': 1.4869281045751634e-05, 'epoch': 7.03}\n",
      "{'loss': 0.6212, 'grad_norm': 5.992237567901611, 'learning_rate': 1.4787581699346405e-05, 'epoch': 7.04}\n",
      "{'loss': 0.6022, 'grad_norm': 4.183780670166016, 'learning_rate': 1.4705882352941177e-05, 'epoch': 7.06}\n",
      "{'loss': 0.6946, 'grad_norm': 6.794656753540039, 'learning_rate': 1.462418300653595e-05, 'epoch': 7.08}\n",
      "{'loss': 0.6494, 'grad_norm': 3.6167409420013428, 'learning_rate': 1.4542483660130721e-05, 'epoch': 7.09}\n",
      "{'loss': 0.6122, 'grad_norm': 5.17732048034668, 'learning_rate': 1.4460784313725493e-05, 'epoch': 7.11}\n",
      "{'loss': 0.6728, 'grad_norm': 5.986691474914551, 'learning_rate': 1.4379084967320261e-05, 'epoch': 7.12}\n",
      "{'loss': 0.6129, 'grad_norm': 4.087143421173096, 'learning_rate': 1.4297385620915032e-05, 'epoch': 7.14}\n",
      "{'loss': 0.6341, 'grad_norm': 8.021775245666504, 'learning_rate': 1.4215686274509804e-05, 'epoch': 7.16}\n",
      "{'loss': 0.6039, 'grad_norm': 3.2244324684143066, 'learning_rate': 1.4133986928104575e-05, 'epoch': 7.17}\n",
      "{'loss': 0.6335, 'grad_norm': 5.938838958740234, 'learning_rate': 1.4052287581699347e-05, 'epoch': 7.19}\n",
      "{'loss': 0.6845, 'grad_norm': 6.959577560424805, 'learning_rate': 1.3970588235294118e-05, 'epoch': 7.21}\n",
      "{'loss': 0.5892, 'grad_norm': 6.275814056396484, 'learning_rate': 1.388888888888889e-05, 'epoch': 7.22}\n",
      "{'loss': 0.7027, 'grad_norm': 3.7724668979644775, 'learning_rate': 1.3807189542483661e-05, 'epoch': 7.24}\n",
      "{'loss': 0.6401, 'grad_norm': 6.454960346221924, 'learning_rate': 1.3725490196078432e-05, 'epoch': 7.25}\n",
      "{'loss': 0.5857, 'grad_norm': 9.091791152954102, 'learning_rate': 1.3643790849673202e-05, 'epoch': 7.27}\n",
      "{'loss': 0.5904, 'grad_norm': 5.615965843200684, 'learning_rate': 1.3562091503267974e-05, 'epoch': 7.29}\n",
      "{'loss': 0.529, 'grad_norm': 7.132758140563965, 'learning_rate': 1.3480392156862745e-05, 'epoch': 7.3}\n",
      "{'loss': 0.6286, 'grad_norm': 6.0419111251831055, 'learning_rate': 1.3398692810457516e-05, 'epoch': 7.32}\n",
      "{'loss': 0.6384, 'grad_norm': 4.198672771453857, 'learning_rate': 1.3316993464052288e-05, 'epoch': 7.34}\n",
      "{'loss': 0.6898, 'grad_norm': 6.498654365539551, 'learning_rate': 1.323529411764706e-05, 'epoch': 7.35}\n",
      "{'loss': 0.6741, 'grad_norm': 6.012022495269775, 'learning_rate': 1.315359477124183e-05, 'epoch': 7.37}\n",
      "{'loss': 0.5547, 'grad_norm': 2.4809417724609375, 'learning_rate': 1.3071895424836602e-05, 'epoch': 7.39}\n",
      "{'loss': 0.7372, 'grad_norm': 4.77497673034668, 'learning_rate': 1.2990196078431374e-05, 'epoch': 7.4}\n",
      "{'loss': 0.7086, 'grad_norm': 6.278813362121582, 'learning_rate': 1.2908496732026145e-05, 'epoch': 7.42}\n",
      "{'loss': 0.6866, 'grad_norm': 5.76354455947876, 'learning_rate': 1.2826797385620915e-05, 'epoch': 7.43}\n",
      "{'loss': 0.5118, 'grad_norm': 4.9268879890441895, 'learning_rate': 1.2745098039215686e-05, 'epoch': 7.45}\n",
      "{'loss': 0.6514, 'grad_norm': 3.506133794784546, 'learning_rate': 1.2663398692810458e-05, 'epoch': 7.47}\n",
      "{'loss': 0.7064, 'grad_norm': 5.353697299957275, 'learning_rate': 1.258169934640523e-05, 'epoch': 7.48}\n",
      "{'loss': 0.5449, 'grad_norm': 4.900201320648193, 'learning_rate': 1.25e-05, 'epoch': 7.5}\n",
      "{'loss': 0.6376, 'grad_norm': 7.62817907333374, 'learning_rate': 1.2418300653594772e-05, 'epoch': 7.52}\n",
      "{'loss': 0.5788, 'grad_norm': 5.429603576660156, 'learning_rate': 1.2336601307189543e-05, 'epoch': 7.53}\n",
      "{'loss': 0.6233, 'grad_norm': 4.094525337219238, 'learning_rate': 1.2254901960784313e-05, 'epoch': 7.55}\n",
      "{'loss': 0.6215, 'grad_norm': 4.225978374481201, 'learning_rate': 1.2173202614379085e-05, 'epoch': 7.57}\n",
      "{'loss': 0.6366, 'grad_norm': 5.342936992645264, 'learning_rate': 1.2091503267973856e-05, 'epoch': 7.58}\n",
      "{'loss': 0.7214, 'grad_norm': 6.108249187469482, 'learning_rate': 1.200980392156863e-05, 'epoch': 7.6}\n",
      "{'loss': 0.6736, 'grad_norm': 6.679035186767578, 'learning_rate': 1.19281045751634e-05, 'epoch': 7.61}\n",
      "{'loss': 0.7523, 'grad_norm': 5.539424419403076, 'learning_rate': 1.184640522875817e-05, 'epoch': 7.63}\n",
      "{'loss': 0.602, 'grad_norm': 5.334962368011475, 'learning_rate': 1.1764705882352942e-05, 'epoch': 7.65}\n",
      "{'loss': 0.6012, 'grad_norm': 5.082416534423828, 'learning_rate': 1.1683006535947713e-05, 'epoch': 7.66}\n",
      "{'loss': 0.7147, 'grad_norm': 4.4476165771484375, 'learning_rate': 1.1601307189542485e-05, 'epoch': 7.68}\n",
      "{'loss': 0.5505, 'grad_norm': 3.851379156112671, 'learning_rate': 1.1519607843137254e-05, 'epoch': 7.7}\n",
      "{'loss': 0.6605, 'grad_norm': 5.41045618057251, 'learning_rate': 1.1437908496732026e-05, 'epoch': 7.71}\n",
      "{'loss': 0.5954, 'grad_norm': 5.477571964263916, 'learning_rate': 1.1356209150326797e-05, 'epoch': 7.73}\n",
      "{'loss': 0.4902, 'grad_norm': 3.3518261909484863, 'learning_rate': 1.1274509803921569e-05, 'epoch': 7.75}\n",
      "{'loss': 0.5985, 'grad_norm': 5.163357257843018, 'learning_rate': 1.119281045751634e-05, 'epoch': 7.76}\n",
      "{'loss': 0.6579, 'grad_norm': 4.613183498382568, 'learning_rate': 1.1111111111111112e-05, 'epoch': 7.78}\n",
      "{'loss': 0.6866, 'grad_norm': 3.5936954021453857, 'learning_rate': 1.1029411764705883e-05, 'epoch': 7.79}\n",
      "{'loss': 0.6828, 'grad_norm': 3.5870490074157715, 'learning_rate': 1.0947712418300655e-05, 'epoch': 7.81}\n",
      "{'loss': 0.5931, 'grad_norm': 3.9672868251800537, 'learning_rate': 1.0866013071895426e-05, 'epoch': 7.83}\n",
      "{'loss': 0.5851, 'grad_norm': 3.043537139892578, 'learning_rate': 1.0784313725490197e-05, 'epoch': 7.84}\n",
      "{'loss': 0.6211, 'grad_norm': 4.3966851234436035, 'learning_rate': 1.0702614379084967e-05, 'epoch': 7.86}\n",
      "{'loss': 0.716, 'grad_norm': 3.485714912414551, 'learning_rate': 1.0620915032679739e-05, 'epoch': 7.88}\n",
      "{'loss': 0.6192, 'grad_norm': 7.113710880279541, 'learning_rate': 1.053921568627451e-05, 'epoch': 7.89}\n",
      "{'loss': 0.7221, 'grad_norm': 4.5662078857421875, 'learning_rate': 1.0457516339869281e-05, 'epoch': 7.91}\n",
      "{'loss': 0.6288, 'grad_norm': 7.4413957595825195, 'learning_rate': 1.0375816993464053e-05, 'epoch': 7.92}\n",
      "{'loss': 0.5799, 'grad_norm': 6.017416954040527, 'learning_rate': 1.0294117647058824e-05, 'epoch': 7.94}\n",
      "{'loss': 0.5841, 'grad_norm': 5.276834964752197, 'learning_rate': 1.0212418300653596e-05, 'epoch': 7.96}\n",
      "{'loss': 0.605, 'grad_norm': 6.157486915588379, 'learning_rate': 1.0130718954248367e-05, 'epoch': 7.97}\n",
      "{'loss': 0.5854, 'grad_norm': 4.8736419677734375, 'learning_rate': 1.0049019607843139e-05, 'epoch': 7.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c97f5607eb442e7b9fbef7ce64ff721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7087445259094238, 'eval_accuracy': 0.576017130620985, 'eval_f1_macro': 0.5585084033613446, 'eval_precision': 0.5621583893673077, 'eval_recall': 0.5591310365465904, 'eval_runtime': 20.7284, 'eval_samples_per_second': 22.529, 'eval_steps_per_second': 5.644, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6423, 'grad_norm': 3.138932943344116, 'learning_rate': 9.96732026143791e-06, 'epoch': 8.01}\n",
      "{'loss': 0.8431, 'grad_norm': 8.598648071289062, 'learning_rate': 9.88562091503268e-06, 'epoch': 8.02}\n",
      "{'loss': 0.6236, 'grad_norm': 6.1877336502075195, 'learning_rate': 9.803921568627451e-06, 'epoch': 8.04}\n",
      "{'loss': 0.609, 'grad_norm': 3.8524911403656006, 'learning_rate': 9.722222222222223e-06, 'epoch': 8.06}\n",
      "{'loss': 0.5626, 'grad_norm': 2.7503130435943604, 'learning_rate': 9.640522875816994e-06, 'epoch': 8.07}\n",
      "{'loss': 0.5504, 'grad_norm': 4.39495325088501, 'learning_rate': 9.558823529411764e-06, 'epoch': 8.09}\n",
      "{'loss': 0.7196, 'grad_norm': 5.505363464355469, 'learning_rate': 9.477124183006535e-06, 'epoch': 8.1}\n",
      "{'loss': 0.6223, 'grad_norm': 3.831146240234375, 'learning_rate': 9.395424836601307e-06, 'epoch': 8.12}\n",
      "{'loss': 0.606, 'grad_norm': 2.973806858062744, 'learning_rate': 9.31372549019608e-06, 'epoch': 8.14}\n",
      "{'loss': 0.5157, 'grad_norm': 5.501428127288818, 'learning_rate': 9.232026143790851e-06, 'epoch': 8.15}\n",
      "{'loss': 0.5815, 'grad_norm': 5.505770206451416, 'learning_rate': 9.150326797385621e-06, 'epoch': 8.17}\n",
      "{'loss': 0.5989, 'grad_norm': 7.189087867736816, 'learning_rate': 9.068627450980392e-06, 'epoch': 8.19}\n",
      "{'loss': 0.6577, 'grad_norm': 6.580686569213867, 'learning_rate': 8.986928104575164e-06, 'epoch': 8.2}\n",
      "{'loss': 0.5807, 'grad_norm': 7.604547023773193, 'learning_rate': 8.905228758169935e-06, 'epoch': 8.22}\n",
      "{'loss': 0.6539, 'grad_norm': 9.206038475036621, 'learning_rate': 8.823529411764707e-06, 'epoch': 8.24}\n",
      "{'loss': 0.7695, 'grad_norm': 5.357763290405273, 'learning_rate': 8.741830065359477e-06, 'epoch': 8.25}\n",
      "{'loss': 0.5889, 'grad_norm': 5.647614002227783, 'learning_rate': 8.660130718954248e-06, 'epoch': 8.27}\n",
      "{'loss': 0.669, 'grad_norm': 4.3909807205200195, 'learning_rate': 8.57843137254902e-06, 'epoch': 8.28}\n",
      "{'loss': 0.6811, 'grad_norm': 6.0731401443481445, 'learning_rate': 8.496732026143791e-06, 'epoch': 8.3}\n",
      "{'loss': 0.7476, 'grad_norm': 4.897503852844238, 'learning_rate': 8.415032679738562e-06, 'epoch': 8.32}\n",
      "{'loss': 0.6888, 'grad_norm': 6.864416599273682, 'learning_rate': 8.333333333333334e-06, 'epoch': 8.33}\n",
      "{'loss': 0.6275, 'grad_norm': 5.17591667175293, 'learning_rate': 8.251633986928105e-06, 'epoch': 8.35}\n",
      "{'loss': 0.6284, 'grad_norm': 3.3571181297302246, 'learning_rate': 8.169934640522877e-06, 'epoch': 8.37}\n",
      "{'loss': 0.587, 'grad_norm': 6.297731399536133, 'learning_rate': 8.088235294117648e-06, 'epoch': 8.38}\n",
      "{'loss': 0.78, 'grad_norm': 3.8723835945129395, 'learning_rate': 8.006535947712418e-06, 'epoch': 8.4}\n",
      "{'loss': 0.5563, 'grad_norm': 7.532017707824707, 'learning_rate': 7.92483660130719e-06, 'epoch': 8.42}\n",
      "{'loss': 0.6588, 'grad_norm': 5.404232978820801, 'learning_rate': 7.84313725490196e-06, 'epoch': 8.43}\n",
      "{'loss': 0.5891, 'grad_norm': 2.9735803604125977, 'learning_rate': 7.761437908496732e-06, 'epoch': 8.45}\n",
      "{'loss': 0.5787, 'grad_norm': 7.558067321777344, 'learning_rate': 7.679738562091504e-06, 'epoch': 8.46}\n",
      "{'loss': 0.5237, 'grad_norm': 3.9873695373535156, 'learning_rate': 7.598039215686274e-06, 'epoch': 8.48}\n",
      "{'loss': 0.5918, 'grad_norm': 7.228468418121338, 'learning_rate': 7.5163398692810456e-06, 'epoch': 8.5}\n",
      "{'loss': 0.6031, 'grad_norm': 3.6769800186157227, 'learning_rate': 7.434640522875817e-06, 'epoch': 8.51}\n",
      "{'loss': 0.5104, 'grad_norm': 5.081928253173828, 'learning_rate': 7.3529411764705884e-06, 'epoch': 8.53}\n",
      "{'loss': 0.5352, 'grad_norm': 4.898109436035156, 'learning_rate': 7.271241830065361e-06, 'epoch': 8.55}\n",
      "{'loss': 0.7013, 'grad_norm': 6.5602521896362305, 'learning_rate': 7.1895424836601305e-06, 'epoch': 8.56}\n",
      "{'loss': 0.6844, 'grad_norm': 5.942820072174072, 'learning_rate': 7.107843137254902e-06, 'epoch': 8.58}\n",
      "{'loss': 0.6724, 'grad_norm': 4.76953125, 'learning_rate': 7.026143790849673e-06, 'epoch': 8.59}\n",
      "{'loss': 0.4918, 'grad_norm': 4.169753551483154, 'learning_rate': 6.944444444444445e-06, 'epoch': 8.61}\n",
      "{'loss': 0.7235, 'grad_norm': 4.087496280670166, 'learning_rate': 6.862745098039216e-06, 'epoch': 8.63}\n",
      "{'loss': 0.5952, 'grad_norm': 3.6080379486083984, 'learning_rate': 6.781045751633987e-06, 'epoch': 8.64}\n",
      "{'loss': 0.6552, 'grad_norm': 7.2504143714904785, 'learning_rate': 6.699346405228758e-06, 'epoch': 8.66}\n",
      "{'loss': 0.5708, 'grad_norm': 3.493886709213257, 'learning_rate': 6.61764705882353e-06, 'epoch': 8.68}\n",
      "{'loss': 0.6299, 'grad_norm': 3.205371141433716, 'learning_rate': 6.535947712418301e-06, 'epoch': 8.69}\n",
      "{'loss': 0.6397, 'grad_norm': 7.713428974151611, 'learning_rate': 6.4542483660130726e-06, 'epoch': 8.71}\n",
      "{'loss': 0.6829, 'grad_norm': 5.596490859985352, 'learning_rate': 6.372549019607843e-06, 'epoch': 8.73}\n",
      "{'loss': 0.6396, 'grad_norm': 4.231074810028076, 'learning_rate': 6.290849673202615e-06, 'epoch': 8.74}\n",
      "{'loss': 0.6208, 'grad_norm': 3.381014585494995, 'learning_rate': 6.209150326797386e-06, 'epoch': 8.76}\n",
      "{'loss': 0.5948, 'grad_norm': 5.990664958953857, 'learning_rate': 6.127450980392157e-06, 'epoch': 8.77}\n",
      "{'loss': 0.6889, 'grad_norm': 5.090579032897949, 'learning_rate': 6.045751633986928e-06, 'epoch': 8.79}\n",
      "{'loss': 0.6198, 'grad_norm': 6.807430744171143, 'learning_rate': 5.9640522875817e-06, 'epoch': 8.81}\n",
      "{'loss': 0.6755, 'grad_norm': 4.83856201171875, 'learning_rate': 5.882352941176471e-06, 'epoch': 8.82}\n",
      "{'loss': 0.5507, 'grad_norm': 4.612057209014893, 'learning_rate': 5.800653594771242e-06, 'epoch': 8.84}\n",
      "{'loss': 0.663, 'grad_norm': 6.661013126373291, 'learning_rate': 5.718954248366013e-06, 'epoch': 8.86}\n",
      "{'loss': 0.6142, 'grad_norm': 3.3383572101593018, 'learning_rate': 5.637254901960784e-06, 'epoch': 8.87}\n",
      "{'loss': 0.5226, 'grad_norm': 2.5380611419677734, 'learning_rate': 5.555555555555556e-06, 'epoch': 8.89}\n",
      "{'loss': 0.5687, 'grad_norm': 5.334788799285889, 'learning_rate': 5.473856209150327e-06, 'epoch': 8.91}\n",
      "{'loss': 0.6917, 'grad_norm': 5.70962381362915, 'learning_rate': 5.392156862745099e-06, 'epoch': 8.92}\n",
      "{'loss': 0.6858, 'grad_norm': 5.7491655349731445, 'learning_rate': 5.310457516339869e-06, 'epoch': 8.94}\n",
      "{'loss': 0.6444, 'grad_norm': 7.078470230102539, 'learning_rate': 5.228758169934641e-06, 'epoch': 8.95}\n",
      "{'loss': 0.6418, 'grad_norm': 3.6733951568603516, 'learning_rate': 5.147058823529412e-06, 'epoch': 8.97}\n",
      "{'loss': 0.676, 'grad_norm': 3.7353577613830566, 'learning_rate': 5.065359477124184e-06, 'epoch': 8.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884bca16542c4af48a63add3cb8ea7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7149356007575989, 'eval_accuracy': 0.5802997858672377, 'eval_f1_macro': 0.5597052258908644, 'eval_precision': 0.5655227774433073, 'eval_recall': 0.5610668462200277, 'eval_runtime': 20.2003, 'eval_samples_per_second': 23.118, 'eval_steps_per_second': 5.792, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5026, 'grad_norm': 4.932605266571045, 'learning_rate': 4.983660130718955e-06, 'epoch': 9.0}\n",
      "{'loss': 0.6047, 'grad_norm': 3.2314531803131104, 'learning_rate': 4.901960784313726e-06, 'epoch': 9.02}\n",
      "{'loss': 0.7665, 'grad_norm': 3.2467434406280518, 'learning_rate': 4.820261437908497e-06, 'epoch': 9.04}\n",
      "{'loss': 0.6548, 'grad_norm': 6.98270320892334, 'learning_rate': 4.738562091503268e-06, 'epoch': 9.05}\n",
      "{'loss': 0.5577, 'grad_norm': 5.059434413909912, 'learning_rate': 4.65686274509804e-06, 'epoch': 9.07}\n",
      "{'loss': 0.5756, 'grad_norm': 6.846188545227051, 'learning_rate': 4.5751633986928105e-06, 'epoch': 9.08}\n",
      "{'loss': 0.6824, 'grad_norm': 4.725461006164551, 'learning_rate': 4.493464052287582e-06, 'epoch': 9.1}\n",
      "{'loss': 0.6087, 'grad_norm': 4.436490535736084, 'learning_rate': 4.411764705882353e-06, 'epoch': 9.12}\n",
      "{'loss': 0.5753, 'grad_norm': 4.109707832336426, 'learning_rate': 4.330065359477124e-06, 'epoch': 9.13}\n",
      "{'loss': 0.6141, 'grad_norm': 5.150399684906006, 'learning_rate': 4.2483660130718954e-06, 'epoch': 9.15}\n",
      "{'loss': 0.6854, 'grad_norm': 7.240765571594238, 'learning_rate': 4.166666666666667e-06, 'epoch': 9.17}\n",
      "{'loss': 0.7177, 'grad_norm': 6.181171417236328, 'learning_rate': 4.084967320261438e-06, 'epoch': 9.18}\n",
      "{'loss': 0.5553, 'grad_norm': 5.379507064819336, 'learning_rate': 4.003267973856209e-06, 'epoch': 9.2}\n",
      "{'loss': 0.6743, 'grad_norm': 3.9817066192626953, 'learning_rate': 3.92156862745098e-06, 'epoch': 9.22}\n",
      "{'loss': 0.5319, 'grad_norm': 5.446195125579834, 'learning_rate': 3.839869281045752e-06, 'epoch': 9.23}\n",
      "{'loss': 0.6072, 'grad_norm': 4.241908550262451, 'learning_rate': 3.7581699346405228e-06, 'epoch': 9.25}\n",
      "{'loss': 0.617, 'grad_norm': 4.553598403930664, 'learning_rate': 3.6764705882352942e-06, 'epoch': 9.26}\n",
      "{'loss': 0.6768, 'grad_norm': 4.460210800170898, 'learning_rate': 3.5947712418300652e-06, 'epoch': 9.28}\n",
      "{'loss': 0.6317, 'grad_norm': 3.6525871753692627, 'learning_rate': 3.5130718954248367e-06, 'epoch': 9.3}\n",
      "{'loss': 0.5664, 'grad_norm': 3.684072494506836, 'learning_rate': 3.431372549019608e-06, 'epoch': 9.31}\n",
      "{'loss': 0.4935, 'grad_norm': 6.5932207107543945, 'learning_rate': 3.349673202614379e-06, 'epoch': 9.33}\n",
      "{'loss': 0.7542, 'grad_norm': 5.547646999359131, 'learning_rate': 3.2679738562091506e-06, 'epoch': 9.35}\n",
      "{'loss': 0.6482, 'grad_norm': 5.660107612609863, 'learning_rate': 3.1862745098039216e-06, 'epoch': 9.36}\n",
      "{'loss': 0.6775, 'grad_norm': 4.317569732666016, 'learning_rate': 3.104575163398693e-06, 'epoch': 9.38}\n",
      "{'loss': 0.6403, 'grad_norm': 4.443017959594727, 'learning_rate': 3.022875816993464e-06, 'epoch': 9.4}\n",
      "{'loss': 0.6406, 'grad_norm': 8.07300090789795, 'learning_rate': 2.9411764705882355e-06, 'epoch': 9.41}\n",
      "{'loss': 0.6766, 'grad_norm': 5.490406513214111, 'learning_rate': 2.8594771241830065e-06, 'epoch': 9.43}\n",
      "{'loss': 0.5795, 'grad_norm': 5.810731887817383, 'learning_rate': 2.777777777777778e-06, 'epoch': 9.44}\n",
      "{'loss': 0.6403, 'grad_norm': 5.01047420501709, 'learning_rate': 2.6960784313725493e-06, 'epoch': 9.46}\n",
      "{'loss': 0.6023, 'grad_norm': 4.674124240875244, 'learning_rate': 2.6143790849673204e-06, 'epoch': 9.48}\n",
      "{'loss': 0.6358, 'grad_norm': 3.3517134189605713, 'learning_rate': 2.532679738562092e-06, 'epoch': 9.49}\n",
      "{'loss': 0.6833, 'grad_norm': 4.094459056854248, 'learning_rate': 2.450980392156863e-06, 'epoch': 9.51}\n",
      "{'loss': 0.7457, 'grad_norm': 5.447208881378174, 'learning_rate': 2.369281045751634e-06, 'epoch': 9.53}\n",
      "{'loss': 0.7341, 'grad_norm': 5.2198028564453125, 'learning_rate': 2.2875816993464053e-06, 'epoch': 9.54}\n",
      "{'loss': 0.658, 'grad_norm': 7.09606409072876, 'learning_rate': 2.2058823529411767e-06, 'epoch': 9.56}\n",
      "{'loss': 0.7578, 'grad_norm': 5.784788131713867, 'learning_rate': 2.1241830065359477e-06, 'epoch': 9.58}\n",
      "{'loss': 0.5601, 'grad_norm': 4.503265857696533, 'learning_rate': 2.042483660130719e-06, 'epoch': 9.59}\n",
      "{'loss': 0.7338, 'grad_norm': 9.390108108520508, 'learning_rate': 1.96078431372549e-06, 'epoch': 9.61}\n",
      "{'loss': 0.5962, 'grad_norm': 7.123587608337402, 'learning_rate': 1.8790849673202614e-06, 'epoch': 9.62}\n",
      "{'loss': 0.6409, 'grad_norm': 8.073112487792969, 'learning_rate': 1.7973856209150326e-06, 'epoch': 9.64}\n",
      "{'loss': 0.6413, 'grad_norm': 6.898354530334473, 'learning_rate': 1.715686274509804e-06, 'epoch': 9.66}\n",
      "{'loss': 0.5177, 'grad_norm': 6.852811813354492, 'learning_rate': 1.6339869281045753e-06, 'epoch': 9.67}\n",
      "{'loss': 0.6369, 'grad_norm': 6.585490703582764, 'learning_rate': 1.5522875816993465e-06, 'epoch': 9.69}\n",
      "{'loss': 0.645, 'grad_norm': 4.663585662841797, 'learning_rate': 1.4705882352941177e-06, 'epoch': 9.71}\n",
      "{'loss': 0.6191, 'grad_norm': 5.144387245178223, 'learning_rate': 1.388888888888889e-06, 'epoch': 9.72}\n",
      "{'loss': 0.6452, 'grad_norm': 3.262495756149292, 'learning_rate': 1.3071895424836602e-06, 'epoch': 9.74}\n",
      "{'loss': 0.5259, 'grad_norm': 7.843751907348633, 'learning_rate': 1.2254901960784314e-06, 'epoch': 9.75}\n",
      "{'loss': 0.5959, 'grad_norm': 5.720303058624268, 'learning_rate': 1.1437908496732026e-06, 'epoch': 9.77}\n",
      "{'loss': 0.5344, 'grad_norm': 6.270484447479248, 'learning_rate': 1.0620915032679739e-06, 'epoch': 9.79}\n",
      "{'loss': 0.5605, 'grad_norm': 4.0966386795043945, 'learning_rate': 9.80392156862745e-07, 'epoch': 9.8}\n",
      "{'loss': 0.6186, 'grad_norm': 7.305797576904297, 'learning_rate': 8.986928104575163e-07, 'epoch': 9.82}\n",
      "{'loss': 0.7041, 'grad_norm': 4.244884967803955, 'learning_rate': 8.169934640522876e-07, 'epoch': 9.84}\n",
      "{'loss': 0.7194, 'grad_norm': 7.377201557159424, 'learning_rate': 7.352941176470589e-07, 'epoch': 9.85}\n",
      "{'loss': 0.5654, 'grad_norm': 4.335106372833252, 'learning_rate': 6.535947712418301e-07, 'epoch': 9.87}\n",
      "{'loss': 0.5784, 'grad_norm': 4.3010334968566895, 'learning_rate': 5.718954248366013e-07, 'epoch': 9.89}\n",
      "{'loss': 0.694, 'grad_norm': 5.951615333557129, 'learning_rate': 4.901960784313725e-07, 'epoch': 9.9}\n",
      "{'loss': 0.6172, 'grad_norm': 7.184612274169922, 'learning_rate': 4.084967320261438e-07, 'epoch': 9.92}\n",
      "{'loss': 0.5465, 'grad_norm': 3.65099835395813, 'learning_rate': 3.2679738562091505e-07, 'epoch': 9.93}\n",
      "{'loss': 0.6568, 'grad_norm': 7.925988674163818, 'learning_rate': 2.4509803921568627e-07, 'epoch': 9.95}\n",
      "{'loss': 0.5236, 'grad_norm': 4.803901195526123, 'learning_rate': 1.6339869281045752e-07, 'epoch': 9.97}\n",
      "{'loss': 0.4628, 'grad_norm': 3.3569495677948, 'learning_rate': 8.169934640522876e-08, 'epoch': 9.98}\n",
      "{'loss': 0.6062, 'grad_norm': 4.4672088623046875, 'learning_rate': 0.0, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe31fdfa421c4897a54a2feb3a399ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7155539393424988, 'eval_accuracy': 0.5717344753747323, 'eval_f1_macro': 0.5532468526384265, 'eval_precision': 0.5572052315473368, 'eval_recall': 0.5541559121684809, 'eval_runtime': 20.8397, 'eval_samples_per_second': 22.409, 'eval_steps_per_second': 5.614, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\peft\\utils\\other.py:611: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 50435b53-f6e4-49f5-aecd-cbd21036d18b)') - silently ignoring the lookup for the file config.json in CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment.\n",
      "  warnings.warn(\n",
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\peft\\utils\\save_and_load.py:195: UserWarning: Could not find a config file in CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 5313.7839, 'train_samples_per_second': 4.603, 'train_steps_per_second': 1.152, 'train_loss': 0.6537797230521059, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03e9d2940d64cb6bb0031820cde060e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/187 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7207608819007874,\n",
       " 'eval_accuracy': 0.5655080213903744,\n",
       " 'eval_f1_macro': 0.5495002992830179,\n",
       " 'eval_precision': 0.5521187469645459,\n",
       " 'eval_recall': 0.550030959752322,\n",
       " 'eval_runtime': 31.8244,\n",
       " 'eval_samples_per_second': 23.504,\n",
       " 'eval_steps_per_second': 5.876,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 9. Trainer ===\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# === 10. Train ===\n",
    "trainer.train()\n",
    "\n",
    "# === 11. Evaluate on test set ===\n",
    "trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95debe27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): BertForSequenceClassification(\n",
       "      (bert): BertModel(\n",
       "        (embeddings): BertEmbeddings(\n",
       "          (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (token_type_embeddings): Embedding(2, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): BertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSdpaSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): BertPooler(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=2, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from peft import PeftModel\n",
    "\n",
    "model_name = \"CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment\"\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, ignore_mismatched_sizes=True )\n",
    "\n",
    "CHECKPOINT_PATH = \"./results/arabic_lora/checkpoint-2448\" \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT_PATH)\n",
    "\n",
    "model = PeftModel.from_pretrained(base_model, CHECKPOINT_PATH)\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1be0341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running evaluation on the competition test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Master\\AN1SEM2\\BioNLP\\CLEF2025-CheckThat\\task1\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e184a05bbfa84f20983cb2d8d0c7ecbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Competition Test Set Results ---\n",
      "Loss: 0.6350\n",
      "Accuracy: 0.6284\n",
      "F1-macro: 0.5710\n",
      "Precision: 0.5697\n",
      "Recall: 0.5743\n",
      "Runtime: 50.3276\n",
      "Samples-per-second: 20.5850\n",
      "Steps-per-second: 1.2920\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "eval_args = TrainingArguments(\n",
    "    output_dir=\"./results/temp_eval\",\n",
    "    per_device_eval_batch_size=16, \n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "eval_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=eval_args,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"\\nRunning evaluation on the competition test set...\")\n",
    "results = eval_trainer.evaluate(eval_dataset=competition_test_dataset)\n",
    "\n",
    "\n",
    "# === 5. Print the Final Results ===\n",
    "print(\"\\n--- Competition Test Set Results ---\")\n",
    "for key, value in results.items():\n",
    "    # Example: 'eval_f1_macro' -> 'F1-Macro'\n",
    "    formatted_key = key.replace(\"eval_\", \"\").replace(\"_\", \"-\").capitalize()\n",
    "    print(f\"{formatted_key}: {value:.4f}\")\n",
    "print(\"------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
